{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6011adf8",
   "metadata": {},
   "source": [
    "# 10 分钟快速上手 fastNLP torch\n",
    "\n",
    "&emsp;&emsp;在这个例子中，我们将使用 BERT 来解决 `conll2003` 数据集中的命名实体识别任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e166c051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8)\n",
      "--2022-08-03 09:35:11--  https://data.deepai.org/conll2003.zip\n",
      "Connecting to 10.176.52.116:3333... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 982975 (960K) [application/x-zip-compressed]\n",
      "Saving to: 'conll2003.zip'\n",
      "\n",
      "conll2003.zip       100%[===================>] 959.94K   586KB/s    in 1.6s    \n",
      "\n",
      "2022-08-03 09:35:15 (586 KB/s) - 'conll2003.zip' saved [982975/982975]\n",
      "\n",
      "/bin/bash: warning: setlocale: LC_ALL: cannot change locale (zh_CN.UTF-8)\n",
      "Archive:  conll2003.zip\n",
      "  inflating: conll2003/metadata      \n",
      "  inflating: conll2003/test.txt      \n",
      "  inflating: conll2003/train.txt     \n",
      "  inflating: conll2003/valid.txt     \n"
     ]
    }
   ],
   "source": [
    "# Linux/Mac 下载数据，并解压\n",
    "import platform\n",
    "if platform.system() != \"Windows\":\n",
    "    !wget https://data.deepai.org/conll2003.zip --no-check-certificate -O conll2003.zip\n",
    "    !unzip -o conll2003.zip -d conll2003\n",
    "# Windows用户请通过复制该url到浏览器下载该数据并解压"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0657dfba",
   "metadata": {},
   "source": [
    "### 1.  数据加载\n",
    "&emsp;&emsp;目前在 ``conll2003`` 目录下有 ``train.txt``, ``test.txt``与``valid.txt`` 三个文件，文件的格式为 [conll格式](https://universaldependencies.org/format.html)，其编码格式为 [BIO](https://blog.csdn.net/HappyRocking/article/details/79716212) 类型。可以通过继承 `fastNLP.io.Loader` 来简化加载过程，继承了 `Loader` 函数后，只需要在实现读取单个文件 `_load()` 函数即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6af272f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total 3 datasets:\n",
      "\ttrain has 14987 instances.\n",
      "\ttest has 3684 instances.\n",
      "\tdev has 3466 instances.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from fastNLP import DataSet, Instance\n",
    "from fastNLP.io import Loader\n",
    "\n",
    "\n",
    "# 继承Loader之后，我们只需要实现其中_load()方法，_load()方法传入一个文件路径，返回一个fastNLP DataSet对象，其目的是读取一个文件。\n",
    "class ConllLoader(Loader):\n",
    "    def _load(self, path):\n",
    "        ds = DataSet()\n",
    "        with open(path, 'r') as f:\n",
    "            segments = []\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line == '':  # 如果为空行，说明需要切换到下一句了。\n",
    "                    if segments:\n",
    "                        raw_words = [s[0] for s in segments]\n",
    "                        raw_target = [s[1] for s in segments]\n",
    "                        # 将一个 sample 插入到 DataSet中\n",
    "                        ds.append(Instance(raw_words=raw_words, raw_target=raw_target))  \n",
    "                    segments = []\n",
    "                else:\n",
    "                    parts = line.split()\n",
    "                    assert len(parts)==4\n",
    "                    segments.append([parts[0], parts[-1]])\n",
    "        return ds\n",
    "    \n",
    "\n",
    "# 直接使用 load() 方法加载数据集, 返回的 data_bundle 是一个 fastNLP.io.DataBundle 对象，该对象相当于将多个 dataset 放置在一起，\n",
    "#  可以方便之后的预处理，DataBundle 支持的接口可以在 ！！！ 查看。\n",
    "data_bundle = ConllLoader().load({\n",
    "    'train': 'conll2003/train.txt',\n",
    "    'test': 'conll2003/test.txt',\n",
    "    'dev': 'conll2003/valid.txt'\n",
    "})\n",
    "\"\"\"\n",
    "也可以通过 ConllLoader().load('conll2003/') 来读取，其原理是load()函数将尝试从'conll2003/'文件夹下寻找文件名称中包含了\n",
    "'train'、'test'和'dev'的文件，并分别读取将其命名为'train'、'test'和'dev'（如文件夹中同一个关键字出现在了多个文件名中将导致报错，\n",
    "此时请通过dict的方式传入路径信息）。但在我们这里的数据里，没有文件包含dev，所以无法直接使用文件夹读取，转而通过dict的方式传入读取的路径，\n",
    "该dict的key也将作为读取的数据集的名称，value即对应的文件路径。\n",
    "\"\"\"\n",
    "\n",
    "print(data_bundle)  # 打印 data_bundle 可以查看包含的 DataSet \n",
    "# data_bundle.get_dataset('train')  # 可以获取单个 dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "57ae314d",
   "metadata": {},
   "source": [
    "#### 2.  数据预处理\n",
    "&emsp;&emsp;接下来，我们将演示如何通过 fastNLP 提供的 `apply` 函数方便快捷地进行预处理。我们需要进行的预处理操作有：  \n",
    "\n",
    "1. 使用 `BertTokenizer` 将文本转换为 index；同时记录每个 word 被 bpe 之后第一个 bpe 的 index，用于得到 word 的 `hidden state`；  \n",
    "2. 使用 [Vocabulary](../../api/generated/fastNLP.core.Vocabulary.rst) 来将 `raw_target` 转换为序号。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9315a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67eb4a29e7de47fc82db2a2897c7c95b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "852ed85fd0c744bba7b72d8761e11b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e55723da684b473ab84d0764cce41fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09:35:38] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Save cache to <span style=\"color: #800080; text-decoration-color: #800080\">/remote-home/shxing/fnlp-doc/fastNLP/d</span> <a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/utils/cache_results.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">cache_results.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/utils/cache_results.py#343\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">343</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #800080; text-decoration-color: #800080\">ocs/source/tutorials/torch/caches/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">c7f74559_cache.pkl</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                    </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">.</span>                                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                    </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09:35:38]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Save cache to \u001b[35m/remote-home/shxing/fnlp-doc/fastNLP/d\u001b[0m \u001b]8;id=171711;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/utils/cache_results.py\u001b\\\u001b[2mcache_results.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=961592;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/utils/cache_results.py#343\u001b\\\u001b[2m343\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[35mocs/source/tutorials/torch/caches/\u001b[0m\u001b[95mc7f74559_cache.pkl\u001b[0m \u001b[2m                    \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[95m.\u001b[0m                                                    \u001b[2m                    \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fastNLP 中提供了BERT, RoBERTa, GPT, BART 模型，更多的预训练模型请直接使用transformers\n",
    "from fastNLP.transformers.torch import BertTokenizer\n",
    "from fastNLP import cache_results, Vocabulary\n",
    "\n",
    "# 使用cache_results来装饰函数，会将函数的返回结果缓存到'caches/{param_hash_id}_cache.pkl'路径中（其中{param_hash_id}是根据\n",
    "#   传递给 process_data 函数参数决定的，因此当函数的参数变化时，会再生成新的缓存文件。如果需要重新生成新的缓存，(a) 可以在调用process_data\n",
    "#   函数时，额外传入一个_refresh=True的参数; 或者（b）删除相应的缓存文件。此外，保存结果时，cache_results默认还会\n",
    "#   记录 process_data 函数源码的hash值，当其源码发生了变动，直接读取缓存会发出警告，以防止在修改预处理代码之后，忘记刷新缓存。）\n",
    "@cache_results('caches/cache.pkl')\n",
    "def process_data(data_bundle, model_name):\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "    def bpe(raw_words):\n",
    "        bpes = [tokenizer.cls_token_id]\n",
    "        first = [0]\n",
    "        first_index = 1  # 记录第一个bpe的位置\n",
    "        for word in raw_words:\n",
    "            bpe = tokenizer.encode(word, add_special_tokens=False)\n",
    "            bpes.extend(bpe)\n",
    "            first.append(first_index)\n",
    "            first_index += len(bpe)\n",
    "        bpes.append(tokenizer.sep_token_id)\n",
    "        first.append(first_index)\n",
    "        return {'input_ids': bpes, 'input_len': len(bpes), 'first': first, 'first_len': len(raw_words)}\n",
    "    # 对data_bundle中每个dataset的每一条数据中的raw_words使用bpe函数，并且将返回的结果加入到每条数据中。\n",
    "    data_bundle.apply_field_more(bpe, field_name='raw_words', num_proc=4)\n",
    "    # 对应我们还有 apply_field() 函数，该函数和 apply_field_more() 的区别在于传入到 apply_field() 中的函数应该返回一个 field 的\n",
    "    #   内容（即不需要用dict包裹了）。此外，我们还提供了 data_bundle.apply() ，传入 apply() 的函数需要支持传入一个Instance对象，\n",
    "    #   更多信息可以参考对应的文档。\n",
    "\n",
    "    # tag的词表，由于这是词表，所以不需要有padding和unk\n",
    "    tag_vocab = Vocabulary(padding=None, unknown=None)\n",
    "    # 从 train 数据的 raw_target 中获取建立词表\n",
    "    tag_vocab.from_dataset(data_bundle.get_dataset('train'), field_name='raw_target')\n",
    "    # 使用词表将每个 dataset 中的raw_target转为数字，并且将写入到target这个field中\n",
    "    tag_vocab.index_dataset(data_bundle.datasets.values(), field_name='raw_target', new_field_name='target')\n",
    "\n",
    "    # 可以将 vocabulary 绑定到 data_bundle 上，方便之后使用。\n",
    "    data_bundle.set_vocab(tag_vocab, field_name='target')\n",
    "\n",
    "    return data_bundle, tokenizer\n",
    "\n",
    "data_bundle, tokenizer = process_data(data_bundle, 'bert-base-cased', _refresh=True)  # 第一次调用耗时较长，第二次调用则会直接读取缓存的文件\n",
    "# data_bundle = process_data(data_bundle, 'bert-base-uncased')  # 由于参数变化，fastNLP 会再次生成新的缓存文件。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80036fcd",
   "metadata": {},
   "source": [
    "### 3. DataLoader  \n",
    "&emsp;&emsp;由于现在的深度学习算法大都基于 mini-batch 进行优化，因此需要将多个 sample 组合成一个 batch 再输入到模型之中。在自然语言处理中，不同的 sample 往往长度不一致，需要进行 padding 操作。在 fastNLP 中，我们使用 `fastNLP.TorchDataLoader` 帮助用户快速进行 padding ，我们使用了 `fastNLP.Collator` 对象来进行 pad ，`Collator` 会在迭代过程中根据第一个 batch 的数据自动判定每个 field 是否可以进行 pad ，可以通过 `Collator.set_pad()` 函数修改某个 field 的 pad 行为。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b91402ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastNLP import prepare_dataloader\n",
    "\n",
    "# 将 data_bundle 中每个 dataset 取出并构造出相应的 DataLoader 对象。返回的 dls 是一个 dict ，包含了 'train', 'test', 'dev' 三个\n",
    "#   fastNLP.TorchDataLoader 对象。\n",
    "dls = prepare_dataloader(data_bundle, batch_size=24) \n",
    "\n",
    "\n",
    "# fastNLP 将默认尝试对所有 field 都进行 pad ，如果当前 field 是不可 pad 的类型，则不进行pad；如果是可以 pad 的类型\n",
    "#   默认使用 0 进行 pad 。\n",
    "for dl in dls.values():\n",
    "    # 可以通过 set_pad 修改 padding 的行为。\n",
    "    dl.set_pad('input_ids', pad_val=tokenizer.pad_token_id)\n",
    "    # 如果希望忽略某个 field ，可以通过 set_ignore 方法。\n",
    "    dl.set_ignore('raw_target')\n",
    "    dl.set_pad('target', pad_val=-100)\n",
    "# 另一种设置的方法是，可以在 dls = prepare_dataloader(data_bundle, batch_size=32) 之前直接调用 \n",
    "#  data_bundle.set_pad('input_ids', pad_val=tokenizer.pad_token_id); data_bundle.set_ignore('raw_target')来进行设置。\n",
    "#  DataSet 也支持这两个方法。\n",
    "# 若此时调用 batch = next(dls['train'])，则 batch 是一个 dict ，其中包含了\n",
    "#  'input_ids': torch.LongTensor([batch_size, max_len])\n",
    "#  'input_len': torch.LongTensor([batch_size])\n",
    "#  'first': torch.LongTensor([batch_size, max_len'])\n",
    "#  'first_len': torch.LongTensor([batch_size])\n",
    "#  'target': torch.LongTensor([batch_size, max_len'-2])\n",
    "#  'raw_words': List[List[str]]  # 因为无法判断，所以 Collator 不会做任何处理"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3583df6d",
   "metadata": {},
   "source": [
    "### 4. 模型准备\n",
    "&emsp;&emsp;传入给fastNLP的模型，需要有两个特殊的方法 ``train_step``、``evaluate_step``，前者默认在 `fastNLP.Trainer` 中进行调用，后者默认在 fastNLP.Evaluator 中调用。如果模型中没有 ``train_step`` 方法，则Trainer会直接使用模型的``forward`` 函数；如果模型没有 ``evaluate_step`` 方法，则Evaluator会直接使用模型的 ``forward`` 函数。``train_step`` 方法（或当其不存在时，``forward`` 方法）的返回值必须为 dict 类型，并且必须包含 ``loss`` 这个 key 。\n",
    "\n",
    "&emsp;&emsp;此外fastNLP会使用形参名匹配的方式进行参数传递，例如以下模型\n",
    "```python\n",
    "class Model(nn.Module):\n",
    "   def train_step(self, x, y):\n",
    "        return {'loss': (x-y).abs().mean()}\n",
    "```\n",
    "fastNLP 将尝试从 `DataLoader` 返回的 batch(假设包含的 `key` 为 `input_ids`, `target`) 中寻找 'x' 和 'y' 这两个 key ，如果没有找到则会报错。有以下的方法可以解决报错\n",
    "- 修改 `train_step` 的参数为 `(input_ids, target)`，以保证和 `DataLoader` 返回的 batch 中的 key 匹配\n",
    "- 修改 `DataLoader` 中返回 batch 的 key 的名字为 `(x, y)`\n",
    "- 在 `Trainer` 中传入参数 `train_input_mapping={'input_ids': 'x', 'target': 'y'}` 将输入进行映射，`train_input_mapping` 也可以是一个函数，更多 `train_input_mapping` 的介绍可以参考文档。\n",
    "\n",
    "``evaluate_step`` 也是使用同样的匹配方式，前两条解决方法是一致的，第三种解决方案中，需要在 `Evaluator` 中传入 `evaluate_input_mapping={'input_ids': 'x', 'target': 'y'}`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdd57987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09:37:51] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> Some weights of the model checkpoint at            <a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/transformers/torch/modeling_utils.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">modeling_utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/transformers/torch/modeling_utils.py#1490\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1490</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         bert-base-uncased were not used when initializing  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         BertModel: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'cls.predictions.decoder.weight'</span>,      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'cls.predictions.bias'</span>,                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'cls.predictions.transform.LayerNorm.weight'</span>,      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'cls.predictions.transform.dense.weight'</span>,          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'cls.predictions.transform.LayerNorm.bias'</span>,        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'cls.seq_relationship.bias'</span>,                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'cls.predictions.transform.dense.bias'</span>,            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'cls.seq_relationship.weight'</span><span style=\"font-weight: bold\">]</span>                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         - This IS expected if you are initializing         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         BertModel from the checkpoint of a model trained   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         on another task or with another architecture <span style=\"font-weight: bold\">(</span>e.g. <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         initializing a BertForSequenceClassification model <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         from a BertForPreTraining model<span style=\"font-weight: bold\">)</span>.                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         - This IS NOT expected if you are initializing     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         BertModel from the checkpoint of a model that you  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         expect to be exactly identical <span style=\"font-weight: bold\">(</span>initializing a     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         BertForSequenceClassification model from a         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         BertForSequenceClassification model<span style=\"font-weight: bold\">)</span>.              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09:37:51]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Some weights of the model checkpoint at            \u001b]8;id=426572;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/transformers/torch/modeling_utils.py\u001b\\\u001b[2mmodeling_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=76042;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/transformers/torch/modeling_utils.py#1490\u001b\\\u001b[2m1490\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         bert-base-uncased were not used when initializing  \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         BertModel: \u001b[1m[\u001b[0m\u001b[32m'cls.predictions.decoder.weight'\u001b[0m,      \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'cls.predictions.bias'\u001b[0m,                            \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'cls.predictions.transform.LayerNorm.weight'\u001b[0m,      \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'cls.predictions.transform.dense.weight'\u001b[0m,          \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'cls.predictions.transform.LayerNorm.bias'\u001b[0m,        \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'cls.seq_relationship.bias'\u001b[0m,                       \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'cls.predictions.transform.dense.bias'\u001b[0m,            \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'cls.seq_relationship.weight'\u001b[0m\u001b[1m]\u001b[0m                     \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         - This IS expected if you are initializing         \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         BertModel from the checkpoint of a model trained   \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         on another task or with another architecture \u001b[1m(\u001b[0me.g. \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         initializing a BertForSequenceClassification model \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         from a BertForPreTraining model\u001b[1m)\u001b[0m.                  \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         - This IS NOT expected if you are initializing     \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         BertModel from the checkpoint of a model that you  \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         expect to be exactly identical \u001b[1m(\u001b[0minitializing a     \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         BertForSequenceClassification model from a         \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         BertForSequenceClassification model\u001b[1m)\u001b[0m.              \u001b[2m                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> All the weights of BertModel were initialized from <a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/transformers/torch/modeling_utils.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">modeling_utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/transformers/torch/modeling_utils.py#1507\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1507</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         the model checkpoint at bert-base-uncased.         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         If your task is similar to the task the model of   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         the checkpoint was trained on, you can already use <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         BertModel for predictions without further          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         training.                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m All the weights of BertModel were initialized from \u001b]8;id=9817;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/transformers/torch/modeling_utils.py\u001b\\\u001b[2mmodeling_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=809135;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/transformers/torch/modeling_utils.py#1507\u001b\\\u001b[2m1507\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         the model checkpoint at bert-base-uncased.         \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         If your task is similar to the task the model of   \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         the checkpoint was trained on, you can already use \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         BertModel for predictions without further          \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         training.                                          \u001b[2m                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from fastNLP.transformers.torch import BertModel\n",
    "from fastNLP import seq_len_to_mask\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class BertNER(nn.Module):\n",
    "    def __init__(self, model_name, num_class, tag_vocab=None):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "        self.mlp = nn.Sequential(nn.Linear(self.bert.config.hidden_size, self.bert.config.hidden_size),\n",
    "                                nn.Dropout(0.3),\n",
    "                                nn.Linear(self.bert.config.hidden_size, num_class))\n",
    "        self.tag_vocab = tag_vocab  # 这里传入 tag_vocab 的目的是为了演示 constrined_decode \n",
    "        if tag_vocab is not None:\n",
    "            self._init_constrained_transition()\n",
    "    \n",
    "    def forward(self, input_ids, input_len, first):\n",
    "        attention_mask = seq_len_to_mask(input_len)\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        first = first.unsqueeze(-1).repeat(1, 1, last_hidden_state.size(-1))\n",
    "        first_bpe_state = last_hidden_state.gather(dim=1, index=first)\n",
    "        first_bpe_state = first_bpe_state[:, 1:-1]  # 删除 cls 和 sep\n",
    "        \n",
    "        pred = self.mlp(first_bpe_state)\n",
    "        return {'pred': pred}\n",
    "    \n",
    "    def train_step(self, input_ids, input_len, first, target):\n",
    "        pred = self(input_ids, input_len, first)['pred']\n",
    "        loss = F.cross_entropy(pred.transpose(1, 2), target)\n",
    "        return {'loss': loss}\n",
    "    \n",
    "    def evaluate_step(self, input_ids, input_len, first):\n",
    "        pred = self(input_ids, input_len, first)['pred'].argmax(dim=-1)\n",
    "        return {'pred': pred}\n",
    "    \n",
    "    def constrained_decode(self, input_ids, input_len, first, first_len):\n",
    "        # 这个函数在推理时，将保证解码出来的 tag 一定不与前一个 tag 矛盾【例如一定不会出现 B-person 后面接着 I-Location 的情况】\n",
    "        # 本身这个需求可以在 Metric 中实现，这里在模型中实现的目的是为了方便演示：如何在fastNLP中使用不同的评测函数\n",
    "        pred = self(input_ids, input_len, first)['pred']\n",
    "        cons_pred = []\n",
    "        for _pred, _len in zip(pred, first_len):\n",
    "            _pred = _pred[:_len]\n",
    "            tags = [_pred[0].argmax(dim=-1).item()]  # 这里就不考虑第一个位置非法的情况了\n",
    "            for i in range(1, _len):\n",
    "                tags.append((_pred[i] + self.transition[tags[-1]]).argmax().item())\n",
    "            cons_pred.append(torch.LongTensor(tags))\n",
    "        cons_pred = pad_sequence(cons_pred, batch_first=True)\n",
    "        return {'pred': cons_pred}\n",
    "    \n",
    "    def _init_constrained_transition(self):\n",
    "        from fastNLP.modules.torch import allowed_transitions\n",
    "        allowed_trans = allowed_transitions(self.tag_vocab)\n",
    "        transition = torch.ones((len(self.tag_vocab), len(self.tag_vocab)))*-100000.0\n",
    "        for s, e in allowed_trans:\n",
    "            transition[s, e] = 0\n",
    "        self.register_buffer('transition', transition)\n",
    "\n",
    "model = BertNER('bert-base-uncased', len(data_bundle.get_vocab('target')), data_bundle.get_vocab('target'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5aeee1e9",
   "metadata": {},
   "source": [
    "### 5. Trainer 的使用\n",
    "&emsp;&emsp;fastNLP 的 `Trainer` 是用于对模型进行训练的部件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6e9a6cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09:37:53] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running evaluator sanity check for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> batches.              <a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/trainer.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">trainer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/trainer.py#661\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">661</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09:37:53]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running evaluator sanity check for \u001b[1;36m2\u001b[0m batches.              \u001b]8;id=551808;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/trainer.py\u001b\\\u001b[2mtrainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=583832;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/trainer.py#661\u001b\\\u001b[2m661\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "532d13f0ce1e4e008314c10a02506599",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69bfd835312462c855e536406f00ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00d75f; text-decoration-color: #00d75f\">+++++++++++++++++++++++++++++ </span><span style=\"font-weight: bold\">Eval. results on Epoch:</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">, Batch:</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #00d75f; text-decoration-color: #00d75f\"> +++++++++++++++++++++++++++++</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;41m+++++++++++++++++++++++++++++ \u001b[0m\u001b[1mEval. results on Epoch:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m, Batch:\u001b[0m\u001b[1;36m0\u001b[0m\u001b[38;5;41m +++++++++++++++++++++++++++++\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"f#f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.38953</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"pre#f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.45941</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"rec#f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.338102</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[1;34m\"f#f\"\u001b[0m: \u001b[1;36m0.38953\u001b[0m,\n",
       "  \u001b[1;34m\"pre#f\"\u001b[0m: \u001b[1;36m0.45941\u001b[0m,\n",
       "  \u001b[1;34m\"rec#f\"\u001b[0m: \u001b[1;36m0.338102\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09:38:47] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> The best performance for monitor f#<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:0</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">38953</span> was  <a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/progress_callback.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">progress_callback.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/progress_callback.py#37\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">37</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         achieved in Epoch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Global Batch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">625</span>. The        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         evaluation result:                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'f#f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.38953</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pre#f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.45941</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'rec#f'</span>:       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.338102</span><span style=\"font-weight: bold\">}</span>                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09:38:47]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m The best performance for monitor f#\u001b[1;92mf:0\u001b[0m.\u001b[1;36m38953\u001b[0m was  \u001b]8;id=832668;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/progress_callback.py\u001b\\\u001b[2mprogress_callback.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=453248;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/progress_callback.py#37\u001b\\\u001b[2m37\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         achieved in Epoch:\u001b[1;36m1\u001b[0m, Global Batch:\u001b[1;36m625\u001b[0m. The        \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         evaluation result:                                \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[1m{\u001b[0m\u001b[32m'f#f'\u001b[0m: \u001b[1;36m0.38953\u001b[0m, \u001b[32m'pre#f'\u001b[0m: \u001b[1;36m0.45941\u001b[0m, \u001b[32m'rec#f'\u001b[0m:       \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[1;36m0.338102\u001b[0m\u001b[1m}\u001b[0m                                         \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading best model from buffer with f#f:  <a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/load_best_model_callback.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">load_best_model_callback.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/load_best_model_callback.py#115\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.38953</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading best model from buffer with f#f:  \u001b]8;id=486989;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/load_best_model_callback.py\u001b\\\u001b[2mload_best_model_callback.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=208507;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/load_best_model_callback.py#115\u001b\\\u001b[2m115\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[1;36m0.38953\u001b[0m\u001b[33m...\u001b[0m                                \u001b[2m                               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch import optim\n",
    "from fastNLP import Trainer, LoadBestModelCallback, TorchWarmupCallback\n",
    "from fastNLP import SpanFPreRecMetric\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "callbacks = [\n",
    "    LoadBestModelCallback(),   # 用于在训练结束之后加载性能最好的model的权重\n",
    "    TorchWarmupCallback()\n",
    "]\n",
    "\n",
    "trainer = Trainer(model=model, train_dataloader=dls['train'], optimizers=optimizer, \n",
    "                  evaluate_dataloaders=dls['dev'], \n",
    "                  metrics={'f': SpanFPreRecMetric(tag_vocab=data_bundle.get_vocab('target'))}, \n",
    "                  n_epochs=1, callbacks=callbacks, \n",
    "                  # 在评测时将 dataloader 中的 first_len 映射 seq_len, 因为 SpanFPreRecMetric.update 接口需要输入一个名为 seq_len 的参数\n",
    "                  evaluate_input_mapping={'first_len': 'seq_len'}, overfit_batches=0,\n",
    "                  device=0, monitor='f#f', fp16=False)  # fp16 为 True 的话，将使用 float16 进行训练。\n",
    "trainer.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c600a450",
   "metadata": {},
   "source": [
    "### 6. Evaluator的使用\n",
    "&emsp;&emsp;fastNLP 中用于评测数据的对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f005485a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c44ca26550e46df8f9483196aa387c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'f#f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.360507</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pre#f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.405441</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'rec#f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.32454</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'f#f'\u001b[0m: \u001b[1;36m0.360507\u001b[0m, \u001b[32m'pre#f'\u001b[0m: \u001b[1;36m0.405441\u001b[0m, \u001b[32m'rec#f'\u001b[0m: \u001b[1;36m0.32454\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'f#f': 0.360507, 'pre#f': 0.405441, 'rec#f': 0.32454}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastNLP import Evaluator\n",
    "from fastNLP import SpanFPreRecMetric\n",
    "\n",
    "evaluator = Evaluator(model=model, dataloaders=dls['test'], \n",
    "                      metrics={'f': SpanFPreRecMetric(tag_vocab=data_bundle.get_vocab('target'))}, \n",
    "                      evaluate_input_mapping={'first_len': 'seq_len'}, \n",
    "                      device=0)\n",
    "evaluator.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4880999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7366d73427b54da184d3cd3e4cd3b4b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'f#f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.394526</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pre#f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.471007</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'rec#f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.339412</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'f#f'\u001b[0m: \u001b[1;36m0.394526\u001b[0m, \u001b[32m'pre#f'\u001b[0m: \u001b[1;36m0.471007\u001b[0m, \u001b[32m'rec#f'\u001b[0m: \u001b[1;36m0.339412\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'f#f': 0.394526, 'pre#f': 0.471007, 'rec#f': 0.339412}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果想评测一下使用 constrained decoding的性能，则可以通过传入 evaluate_fn 指定使用的函数\n",
    "def input_mapping(x):\n",
    "    x['seq_len'] = x['first_len']\n",
    "    return x\n",
    "evaluator = Evaluator(model=model, dataloaders=dls['test'], device=0,\n",
    "                      metrics={'f': SpanFPreRecMetric(tag_vocab=data_bundle.get_vocab('target'))},\n",
    "                      evaluate_fn='constrained_decode',\n",
    "                      # 如果将 first_len 重新命名为了 seq_len, 将导致 constrained_decode 的输入缺少 first_len 参数，因此\n",
    "                      #   额外重复一下 'first_len': 'first_len'，使得这个参数不会消失。\n",
    "                      evaluate_input_mapping=input_mapping)\n",
    "evaluator.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a91f86c",
   "metadata": {},
   "source": [
    "### 7. 其它\n",
    "\n",
    "#### 7.1 使用多卡进行训练、评测\n",
    "\n",
    "&emsp;&emsp;fastNLP 同样也支持分布式训练，并且提供了多种使用方式，您可以根据您的使用习惯选择适合您的方法。\n",
    "\n",
    "&emsp;&emsp;最简单的方法就是将 `Trainer` 和 `Evaluator` 的 `device` 参数设置成多卡，然后直接运行即可。如果想要使用设备0, 1进行分布式训练，将 `device` 设置为 `[0,1]` 即可。\n",
    "\n",
    "```python\n",
    "trainer = Trainer(model=model, train_dataloader=dls['train'], optimizers=optimizer, \n",
    "                  evaluate_dataloaders=dls['dev'], \n",
    "                  metrics={'f': SpanFPreRecMetric(tag_vocab=data_bundle.get_vocab('target'))}, \n",
    "                  n_epochs=1, callbacks=callbacks, \n",
    "                  evaluate_input_mapping={'first_len': 'seq_len'}, overfit_batches=0,\n",
    "                  device=[0,1], monitor='f#f', fp16=False)  # 改动的地方只有 device\n",
    "trainer.run()\n",
    "\n",
    "evaluator = Evaluator(model=model, dataloaders=dls['test'], device=[0,1], # 改动的地方只有 device\n",
    "                      metrics={'f': SpanFPreRecMetric(tag_vocab=data_bundle.get_vocab('target'))},\n",
    "                      evaluate_fn='constrained_decode',\n",
    "                      evaluate_input_mapping=input_mapping)\n",
    "evaluator.run()\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2205b261",
   "metadata": {},
   "source": [
    "&emsp;&emsp;第二种方法则不需要对代码做出任何改变，然后通过 `python -m torch.distributed.run` 启动分布式训练。注意，通过该方法启动时，关于gpu设备的分配将完全按照命令行的参数进行，代码中 `device` 的值会被 fastNLP 忽略。详情可以查阅 pytorch 关于分布式训练的说明。\n",
    "\n",
    "&emsp;&emsp;第三种方法则更加接近 pytorch 分布式训练原本的语法。您可以在使用 Trainer 之前初始化分布式中的通信组，然后使用 `DistributedDataParallel` 包裹模型，最后通过指令 `python -m torch.distributed.run` 进行分布式训练。这种使用方式依据 pytorch 分布式训练的流程，更加适合此前经常使用分布式训练的用户。不过需要注意的是，您需要为 Trainer 和 Evaluator 指定 `data_device` 参数来告诉 fastNLP 应该将数据迁移到哪个设备上。\n",
    "\n",
    "```python\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "\n",
    "# 初始化通信组\n",
    "dist.init_process_group()\n",
    "# 分布式模型\n",
    "model = DistributedDataParallel(model)\n",
    "# 找到每个 rank 对应的设备\n",
    "local_rank = int(os.environ['LOCAL_RANK'])\n",
    "local_device = torch.device(f\"cuda:{local_rank}\")\n",
    "\n",
    "trainer = Trainer(model=model, train_dataloader=dls['train'], optimizers=optimizer, \n",
    "                  evaluate_dataloaders=dls['dev'], \n",
    "                  metrics={'f': SpanFPreRecMetric(tag_vocab=data_bundle.get_vocab('target'))}, \n",
    "                  n_epochs=1, callbacks=callbacks, \n",
    "                  evaluate_input_mapping={'first_len': 'seq_len'}, overfit_batches=0,\n",
    "                  device=None, data_device=local_device, monitor='f#f', fp16=False)  # device 参数会被忽略，并且需要指定 data_device\n",
    "trainer.run()\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c163ede2",
   "metadata": {},
   "source": [
    "&emsp;&emsp;#### 7.2 使用ZeRO优化\n",
    "\n",
    "在最新版本的 torch 1.12 中，pytorch 加入了 `fully sharded data parallel` 的并行策略，对标微软 `deepspeed` 提出的 ZeRO 优化，帮助我们节省训练中的内存。fastNLP也加入了该功能，只需要将 `driver` 参数指定为 `'torch_fsdp'` 即可，其它的使用方法则和上文提到的 **分布式训练** 相似。您可以查阅 [fastNLP 关于 fsdp 的说明](../../api/generated/fastNLP.core.TorchFSDPDriver.rst) 和 [pytorch 的官方教程](https://pytorch.org/tutorials/intermediate/FSDP_tutorial.html) 来进行更加深入的了解。\n",
    "\n",
    "```python\n",
    "trainer = Trainer(model=model, driver='torch_fsdp', train_dataloader=dls['train'], # 指定 driver\n",
    "                  optimizers=optimizer, evaluate_dataloaders=dls['dev'], \n",
    "                  metrics={'f': SpanFPreRecMetric(tag_vocab=data_bundle.get_vocab('target'))}, \n",
    "                  n_epochs=1, callbacks=callbacks, \n",
    "                  evaluate_input_mapping={'first_len': 'seq_len'}, overfit_batches=0,\n",
    "                  device=[0,1], monitor='f#f', fp16=False)\n",
    "trainer.run()\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f064e040",
   "metadata": {},
   "source": [
    "#### 7.3 通过overfit测试快速验证模型\n",
    "\n",
    "&emsp;&emsp;在训练模型时我们往往难以验证模型和数据的正确性，以及各种训练参数的设置也不好判断。fastNLP 中 Trainer 提供的 `overfit_batches` 参数可以帮您简单地进行验证。指定该参数后，fastNLP 会将训练集中的 `overfit_batches` 个 batch （如果为-1则为全部）同时作为此次训练集和验证集开始训练，即训练集和验证集都是同一个数据集。如果一切设置正常，那么训练的结果应该在数次迭代之后趋于过拟合（如在分类任务中准确率会达到95%以上甚至100%）。如果结果并不理想，就需要考虑是否有数据中存在矛盾、学习率选择不当、模型结构不当等问题了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83c99faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09:39:42] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> Some weights of the model checkpoint at            <a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/transformers/torch/modeling_utils.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">modeling_utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/transformers/torch/modeling_utils.py#1490\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1490</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         bert-base-uncased were not used when initializing  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         BertModel: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'cls.predictions.decoder.weight'</span>,      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'cls.predictions.bias'</span>,                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'cls.predictions.transform.LayerNorm.weight'</span>,      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'cls.predictions.transform.dense.weight'</span>,          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'cls.predictions.transform.LayerNorm.bias'</span>,        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'cls.seq_relationship.bias'</span>,                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'cls.predictions.transform.dense.bias'</span>,            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'cls.seq_relationship.weight'</span><span style=\"font-weight: bold\">]</span>                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         - This IS expected if you are initializing         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         BertModel from the checkpoint of a model trained   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         on another task or with another architecture <span style=\"font-weight: bold\">(</span>e.g. <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         initializing a BertForSequenceClassification model <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         from a BertForPreTraining model<span style=\"font-weight: bold\">)</span>.                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         - This IS NOT expected if you are initializing     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         BertModel from the checkpoint of a model that you  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         expect to be exactly identical <span style=\"font-weight: bold\">(</span>initializing a     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         BertForSequenceClassification model from a         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         BertForSequenceClassification model<span style=\"font-weight: bold\">)</span>.              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09:39:42]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Some weights of the model checkpoint at            \u001b]8;id=735419;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/transformers/torch/modeling_utils.py\u001b\\\u001b[2mmodeling_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=171018;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/transformers/torch/modeling_utils.py#1490\u001b\\\u001b[2m1490\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         bert-base-uncased were not used when initializing  \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         BertModel: \u001b[1m[\u001b[0m\u001b[32m'cls.predictions.decoder.weight'\u001b[0m,      \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'cls.predictions.bias'\u001b[0m,                            \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'cls.predictions.transform.LayerNorm.weight'\u001b[0m,      \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'cls.predictions.transform.dense.weight'\u001b[0m,          \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'cls.predictions.transform.LayerNorm.bias'\u001b[0m,        \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'cls.seq_relationship.bias'\u001b[0m,                       \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'cls.predictions.transform.dense.bias'\u001b[0m,            \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'cls.seq_relationship.weight'\u001b[0m\u001b[1m]\u001b[0m                     \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         - This IS expected if you are initializing         \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         BertModel from the checkpoint of a model trained   \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         on another task or with another architecture \u001b[1m(\u001b[0me.g. \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         initializing a BertForSequenceClassification model \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         from a BertForPreTraining model\u001b[1m)\u001b[0m.                  \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         - This IS NOT expected if you are initializing     \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         BertModel from the checkpoint of a model that you  \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         expect to be exactly identical \u001b[1m(\u001b[0minitializing a     \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         BertForSequenceClassification model from a         \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         BertForSequenceClassification model\u001b[1m)\u001b[0m.              \u001b[2m                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> All the weights of BertModel were initialized from <a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/transformers/torch/modeling_utils.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">modeling_utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/transformers/torch/modeling_utils.py#1507\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1507</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         the model checkpoint at bert-base-uncased.         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         If your task is similar to the task the model of   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         the checkpoint was trained on, you can already use <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         BertModel for predictions without further          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         training.                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m All the weights of BertModel were initialized from \u001b]8;id=121799;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/transformers/torch/modeling_utils.py\u001b\\\u001b[2mmodeling_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=89897;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/transformers/torch/modeling_utils.py#1507\u001b\\\u001b[2m1507\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         the model checkpoint at bert-base-uncased.         \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         If your task is similar to the task the model of   \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         the checkpoint was trained on, you can already use \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         BertModel for predictions without further          \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         training.                                          \u001b[2m                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09:39:43] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running evaluator sanity check for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> batches.              <a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/trainer.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">trainer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/trainer.py#661\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">661</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09:39:43]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running evaluator sanity check for \u001b[1;36m2\u001b[0m batches.              \u001b]8;id=667061;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/trainer.py\u001b\\\u001b[2mtrainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=768833;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/trainer.py#661\u001b\\\u001b[2m661\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cbd0172e0114e6e847465765b3f6fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68ef2f5b0ff54ed4921286d57b8fd0a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00d75f; text-decoration-color: #00d75f\">++++++++++++++++++++++++++++ </span><span style=\"font-weight: bold\">Eval. results on Epoch:</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span><span style=\"font-weight: bold\">, Batch:</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #00d75f; text-decoration-color: #00d75f\"> +++++++++++++++++++++++++++++</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;41m++++++++++++++++++++++++++++ \u001b[0m\u001b[1mEval. results on Epoch:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1m, Batch:\u001b[0m\u001b[1;36m0\u001b[0m\u001b[38;5;41m +++++++++++++++++++++++++++++\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"f#f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.172316</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"pre#f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.193651</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"rec#f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.155216</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[1;34m\"f#f\"\u001b[0m: \u001b[1;36m0.172316\u001b[0m,\n",
       "  \u001b[1;34m\"pre#f\"\u001b[0m: \u001b[1;36m0.193651\u001b[0m,\n",
       "  \u001b[1;34m\"rec#f\"\u001b[0m: \u001b[1;36m0.155216\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00d75f; text-decoration-color: #00d75f\">++++++++++++++++++++++++++++ </span><span style=\"font-weight: bold\">Eval. results on Epoch:</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span><span style=\"font-weight: bold\">, Batch:</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #00d75f; text-decoration-color: #00d75f\"> +++++++++++++++++++++++++++++</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;41m++++++++++++++++++++++++++++ \u001b[0m\u001b[1mEval. results on Epoch:\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1m, Batch:\u001b[0m\u001b[1;36m0\u001b[0m\u001b[38;5;41m +++++++++++++++++++++++++++++\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"f#f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.695444</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"pre#f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.657596</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"rec#f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.737913</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[1;34m\"f#f\"\u001b[0m: \u001b[1;36m0.695444\u001b[0m,\n",
       "  \u001b[1;34m\"pre#f\"\u001b[0m: \u001b[1;36m0.657596\u001b[0m,\n",
       "  \u001b[1;34m\"rec#f\"\u001b[0m: \u001b[1;36m0.737913\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00d75f; text-decoration-color: #00d75f\">++++++++++++++++++++++++++++ </span><span style=\"font-weight: bold\">Eval. results on Epoch:</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span><span style=\"font-weight: bold\">, Batch:</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #00d75f; text-decoration-color: #00d75f\"> +++++++++++++++++++++++++++++</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;41m++++++++++++++++++++++++++++ \u001b[0m\u001b[1mEval. results on Epoch:\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1m, Batch:\u001b[0m\u001b[1;36m0\u001b[0m\u001b[38;5;41m +++++++++++++++++++++++++++++\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"f#f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.988564</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"pre#f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.98731</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"rec#f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.989822</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[1;34m\"f#f\"\u001b[0m: \u001b[1;36m0.988564\u001b[0m,\n",
       "  \u001b[1;34m\"pre#f\"\u001b[0m: \u001b[1;36m0.98731\u001b[0m,\n",
       "  \u001b[1;34m\"rec#f\"\u001b[0m: \u001b[1;36m0.989822\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09:40:06] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> The best performance for monitor f#<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:0</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">988564</span> was <a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/progress_callback.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">progress_callback.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/progress_callback.py#37\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">37</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         achieved in Epoch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span>, Global Batch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">300</span>. The       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         evaluation result:                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'f#f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.988564</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pre#f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.98731</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'rec#f'</span>:      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.989822</span><span style=\"font-weight: bold\">}</span>                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09:40:06]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m The best performance for monitor f#\u001b[1;92mf:0\u001b[0m.\u001b[1;36m988564\u001b[0m was \u001b]8;id=605298;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/progress_callback.py\u001b\\\u001b[2mprogress_callback.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=30799;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/progress_callback.py#37\u001b\\\u001b[2m37\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         achieved in Epoch:\u001b[1;36m30\u001b[0m, Global Batch:\u001b[1;36m300\u001b[0m. The       \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         evaluation result:                                \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[1m{\u001b[0m\u001b[32m'f#f'\u001b[0m: \u001b[1;36m0.988564\u001b[0m, \u001b[32m'pre#f'\u001b[0m: \u001b[1;36m0.98731\u001b[0m, \u001b[32m'rec#f'\u001b[0m:      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[1;36m0.989822\u001b[0m\u001b[1m}\u001b[0m                                         \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 重新初始化\n",
    "model = BertNER('bert-base-uncased', len(data_bundle.get_vocab('target')), data_bundle.get_vocab('target'))\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "callbacks = [\n",
    "    TorchWarmupCallback()\n",
    "]\n",
    "\n",
    "trainer = Trainer(model=model, train_dataloader=dls['train'], optimizers=optimizer, \n",
    "                  evaluate_dataloaders=dls['dev'], \n",
    "                  metrics={'f': SpanFPreRecMetric(tag_vocab=data_bundle.get_vocab('target'))}, \n",
    "                  n_epochs=30, evaluate_every=-10, # 每 10 个 epoch 查看一次\n",
    "                  evaluate_input_mapping={'first_len': 'seq_len'},\n",
    "                  device=0, monitor='f#f', fp16=False, overfit_batches=10)  # 在训练集的前 10 个 batch 上进行过拟合验证\n",
    "trainer.run() # 最终结果会趋近于 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8062353a",
   "metadata": {},
   "source": [
    "#### 7.4 复杂Monitor的使用\n",
    "\n",
    "&emsp;&emsp;fastNLP 的 Trainer 含有一个参数 `monitor` ，该参数表示在训练中会检测该参数代表的值并按条件执行相应功能。需要注意的是，仅当用户传入的 `Callback` 需要该参数 `Callback` 的 `monitor` 为 `None` 时，Trainer 中的 `monitor` 才会起作用。具体而言，在上文训练 conll 数据集的过程中，我们传入了 `LoadBestModelCallback`，它的功能就是在 `monitor` 变得更好时保存模型，并在训练结束后将这个最好的模型加载回来。在训练过程中，fastNLP 支持更加灵活的 Monitor 设置，帮助您自由地监控您想要查看的变量或结果。当 `monitor` 为 `'f#f'` 时表示保存评测结果中 `f#f` 最好的模型。除了字符串之外，fastNLP 也支持将 `monitor` 作为一个函数。这个函数接受一个字典输入（代表评估的结果），返回一个浮点数作为结果。比如我们可以利用评测结果中的 `pre` 和 `rec` 来手动计算 F1 分数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ad64d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09:40:25] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running evaluator sanity check for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> batches.              <a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/trainer.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">trainer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/trainer.py#661\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">661</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09:40:25]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running evaluator sanity check for \u001b[1;36m2\u001b[0m batches.              \u001b]8;id=220796;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/trainer.py\u001b\\\u001b[2mtrainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=692323;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/trainer.py#661\u001b\\\u001b[2m661\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea0048258a74e56b336fb8ca5e5955b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22f97c55f8744538ea0826f42c5d7f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00d75f; text-decoration-color: #00d75f\">+++++++++++++++++++++++++++++ </span><span style=\"font-weight: bold\">Eval. results on Epoch:</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">, Batch:</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #00d75f; text-decoration-color: #00d75f\"> +++++++++++++++++++++++++++++</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;41m+++++++++++++++++++++++++++++ \u001b[0m\u001b[1mEval. results on Epoch:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m, Batch:\u001b[0m\u001b[1;36m0\u001b[0m\u001b[38;5;41m +++++++++++++++++++++++++++++\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"f#f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.515854</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"pre#f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.560513</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"rec#f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.477785</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[1;34m\"f#f\"\u001b[0m: \u001b[1;36m0.515854\u001b[0m,\n",
       "  \u001b[1;34m\"pre#f\"\u001b[0m: \u001b[1;36m0.560513\u001b[0m,\n",
       "  \u001b[1;34m\"rec#f\"\u001b[0m: \u001b[1;36m0.477785\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09:41:22] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> The best performance for monitor <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">function</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span>       <a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/progress_callback.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">progress_callback.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/progress_callback.py#37\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">37</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #000000; text-decoration-color: #000000\">monitor_ff at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7fb0de601710</span><span style=\"font-weight: bold\">&gt;</span>:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5158532592858202</span>  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         was achieved in Epoch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Global Batch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">625</span>. The    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         evaluation result:                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'f#f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.515854</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pre#f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.560513</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'rec#f'</span>:     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.477785</span><span style=\"font-weight: bold\">}</span>                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09:41:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m The best performance for monitor \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m \u001b[0m       \u001b]8;id=957685;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/progress_callback.py\u001b\\\u001b[2mprogress_callback.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=923072;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/progress_callback.py#37\u001b\\\u001b[2m37\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[39mmonitor_ff at \u001b[0m\u001b[1;36m0x7fb0de601710\u001b[0m\u001b[1m>\u001b[0m:\u001b[1;36m0.5158532592858202\u001b[0m  \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         was achieved in Epoch:\u001b[1;36m1\u001b[0m, Global Batch:\u001b[1;36m625\u001b[0m. The    \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         evaluation result:                                \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[1m{\u001b[0m\u001b[32m'f#f'\u001b[0m: \u001b[1;36m0.515854\u001b[0m, \u001b[32m'pre#f'\u001b[0m: \u001b[1;36m0.560513\u001b[0m, \u001b[32m'rec#f'\u001b[0m:     \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[1;36m0.477785\u001b[0m\u001b[1m}\u001b[0m                                         \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading best model from buffer with       <a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/load_best_model_callback.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">load_best_model_callback.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/load_best_model_callback.py#115\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">function</span><span style=\"color: #000000; text-decoration-color: #000000\"> monitor_ff at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x7fb0de601710</span><span style=\"font-weight: bold\">&gt;</span>:  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5158532592858202</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading best model from buffer with       \u001b]8;id=386040;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/load_best_model_callback.py\u001b\\\u001b[2mload_best_model_callback.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=305206;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/load_best_model_callback.py#115\u001b\\\u001b[2m115\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[1m<\u001b[0m\u001b[1;95mfunction\u001b[0m\u001b[39m monitor_ff at \u001b[0m\u001b[1;36m0x7fb0de601710\u001b[0m\u001b[1m>\u001b[0m:  \u001b[2m                               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[1;36m0.5158532592858202\u001b[0m\u001b[33m...\u001b[0m                     \u001b[2m                               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 重新初始化\n",
    "# model = BertNER('bert-base-uncased', len(data_bundle.get_vocab('target')), data_bundle.get_vocab('target'))\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "callbacks = [\n",
    "    LoadBestModelCallback(),   # 用于在训练结束之后加载性能最好的model的权重\n",
    "    TorchWarmupCallback()\n",
    "]\n",
    "\n",
    "\"\"\"\n",
    "用pre rec重新算一下F值\n",
    "\"\"\"\n",
    "def monitor_ff(result):\n",
    "    # F1 = (1 + beta^2) * pre * rec / (beta^2 * pre + rec + 1e-13)\n",
    "    beta = 1\n",
    "    pre, rec = result[\"pre#f\"], result[\"rec#f\"]\n",
    "    return (1 + beta ** 2) * pre * rec / (beta ** 2 * pre + rec + 1e-13)\n",
    "\n",
    "trainer = Trainer(model=model, train_dataloader=dls['train'], optimizers=optimizer,\n",
    "                  evaluate_dataloaders=dls['dev'], metrics={'f': SpanFPreRecMetric(tag_vocab=data_bundle.get_vocab('target'))}, \n",
    "                  n_epochs=1, callbacks=callbacks, \n",
    "                  evaluate_input_mapping={'first_len': 'seq_len'}, overfit_batches=0,\n",
    "                  device=0, monitor=monitor_ff, fp16=False) # 向 monitor 中传入 monitor_ff 函数\n",
    "trainer.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e5cec212",
   "metadata": {},
   "source": [
    "&emsp;&emsp;您可以根据需要在函数中实现更加复杂的功能以满足不同的需求。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d576d47",
   "metadata": {},
   "source": [
    "#### 7.5 训练过程中，使用不同的测试函数\n",
    "\n",
    "&emsp;&emsp;如您所见，如果仅通过 `model.evaluate_step` 进行验证的话会有许多局限性，而有时我们会需要不同的函数进行评测，例如在大部分生成任务中，一般使用训练 loss 作为训练过程中的 evaluate ；但同时在训练到一定 epoch 数量之后，会让 model 生成的完整的数据评测 bleu 等。此刻就可能需要两种不同的 `evaluate_fn` 。 fastNLP 提供了 `MoreEvaluateCallback` 来实现这一功能。假如我们想要在上文训练 conll 数据集时使用 `ClassifyFPreRecMetric` 并且用不同的频率进行验证（仅作为演示，实际上这两种 Metric 是用于不同任务的），那么可以进行如下的设置："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7508e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025d4e1660934bb58d741c8c05cfdd9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'f#more_f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.368421</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pre#more_f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.368421</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'rec#more_f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.368421</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'f#more_f'\u001b[0m: \u001b[1;36m0.368421\u001b[0m, \u001b[32m'pre#more_f'\u001b[0m: \u001b[1;36m0.368421\u001b[0m, \u001b[32m'rec#more_f'\u001b[0m: \u001b[1;36m0.368421\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09:41:42] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running evaluator sanity check for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> batches.              <a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/trainer.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">trainer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/trainer.py#661\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">661</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09:41:42]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running evaluator sanity check for \u001b[1;36m2\u001b[0m batches.              \u001b]8;id=2342;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/trainer.py\u001b\\\u001b[2mtrainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=17402;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/trainer.py#661\u001b\\\u001b[2m661\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8de9ab55907b4bf38a62bc1d7feca69f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e29bff659f4d7e861566edd9932960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'f#more_f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.369881</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pre#more_f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.369881</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'rec#more_f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.369881</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'f#more_f'\u001b[0m: \u001b[1;36m0.369881\u001b[0m, \u001b[32m'pre#more_f'\u001b[0m: \u001b[1;36m0.369881\u001b[0m, \u001b[32m'rec#more_f'\u001b[0m: \u001b[1;36m0.369881\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'f#more_f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.374074</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pre#more_f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.374074</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'rec#more_f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.374074</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'f#more_f'\u001b[0m: \u001b[1;36m0.374074\u001b[0m, \u001b[32m'pre#more_f'\u001b[0m: \u001b[1;36m0.374074\u001b[0m, \u001b[32m'rec#more_f'\u001b[0m: \u001b[1;36m0.374074\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'f#more_f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.375479</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pre#more_f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.375479</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'rec#more_f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.375479</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'f#more_f'\u001b[0m: \u001b[1;36m0.375479\u001b[0m, \u001b[32m'pre#more_f'\u001b[0m: \u001b[1;36m0.375479\u001b[0m, \u001b[32m'rec#more_f'\u001b[0m: \u001b[1;36m0.375479\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00d75f; text-decoration-color: #00d75f\">+++++++++++++++++++++++++++++ </span><span style=\"font-weight: bold\">Eval. results on Epoch:</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">, Batch:</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #00d75f; text-decoration-color: #00d75f\"> +++++++++++++++++++++++++++++</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;41m+++++++++++++++++++++++++++++ \u001b[0m\u001b[1mEval. results on Epoch:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m, Batch:\u001b[0m\u001b[1;36m0\u001b[0m\u001b[38;5;41m +++++++++++++++++++++++++++++\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"f#f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.626038</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"pre#f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.651501</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"rec#f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.602491</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[1;34m\"f#f\"\u001b[0m: \u001b[1;36m0.626038\u001b[0m,\n",
       "  \u001b[1;34m\"pre#f\"\u001b[0m: \u001b[1;36m0.651501\u001b[0m,\n",
       "  \u001b[1;34m\"rec#f\"\u001b[0m: \u001b[1;36m0.602491\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09:42:44] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> The best performance for monitor f#<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:0</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">626038</span> was <a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/progress_callback.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">progress_callback.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/progress_callback.py#37\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">37</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         achieved in Epoch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Global Batch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">625</span>. The        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         evaluation result:                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'f#f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.626038</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pre#f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.651501</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'rec#f'</span>:     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.602491</span><span style=\"font-weight: bold\">}</span>                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09:42:44]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m The best performance for monitor f#\u001b[1;92mf:0\u001b[0m.\u001b[1;36m626038\u001b[0m was \u001b]8;id=725797;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/progress_callback.py\u001b\\\u001b[2mprogress_callback.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=317286;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/progress_callback.py#37\u001b\\\u001b[2m37\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         achieved in Epoch:\u001b[1;36m1\u001b[0m, Global Batch:\u001b[1;36m625\u001b[0m. The        \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         evaluation result:                                \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[1m{\u001b[0m\u001b[32m'f#f'\u001b[0m: \u001b[1;36m0.626038\u001b[0m, \u001b[32m'pre#f'\u001b[0m: \u001b[1;36m0.651501\u001b[0m, \u001b[32m'rec#f'\u001b[0m:     \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[1;36m0.602491\u001b[0m\u001b[1m}\u001b[0m                                         \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading best model from buffer with f#f:  <a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/load_best_model_callback.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">load_best_model_callback.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/load_best_model_callback.py#115\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.626038</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading best model from buffer with f#f:  \u001b]8;id=725461;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/load_best_model_callback.py\u001b\\\u001b[2mload_best_model_callback.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=596321;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/load_best_model_callback.py#115\u001b\\\u001b[2m115\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[1;36m0.626038\u001b[0m\u001b[33m...\u001b[0m                               \u001b[2m                               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastNLP import MoreEvaluateCallback\n",
    "from fastNLP import ClassifyFPreRecMetric\n",
    "\n",
    "# 重新初始化\n",
    "# model = BertNER('bert-base-uncased', len(data_bundle.get_vocab('target')), data_bundle.get_vocab('target'))\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "callbacks = [\n",
    "    LoadBestModelCallback(),   # 用于在训练结束之后加载性能最好的model的权重\n",
    "    TorchWarmupCallback(),\n",
    "    MoreEvaluateCallback(\n",
    "        dls['dev'], # 设置要验证的 dataloader\n",
    "        metrics={'more_f': ClassifyFPreRecMetric(tag_vocab=data_bundle.get_vocab('target'))}, # metric\n",
    "        evaluate_every=200, # 每 200 个 batch 触发一次\n",
    "    )\n",
    "]\n",
    "\n",
    "trainer = Trainer(model=model, train_dataloader=dls['train'], optimizers=optimizer, \n",
    "                  evaluate_dataloaders=dls['dev'], \n",
    "                  metrics={'f': SpanFPreRecMetric(tag_vocab=data_bundle.get_vocab('target'))}, \n",
    "                  n_epochs=1, callbacks=callbacks, \n",
    "                  evaluate_input_mapping={'first_len': 'seq_len'}, overfit_batches=0,\n",
    "                  device=0, monitor='f#f', fp16=False)\n",
    "trainer.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be6fa28a",
   "metadata": {},
   "source": [
    "&emsp;&emsp;可以看到输出中多出了后缀为 `more_f` 的结果。您可以查阅 [MoreEvaluateCallback 的文档](../../api/generated/fastNLP.core.MoreEvaluateCallback.rst) 来了解更多的参数。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6aa164e",
   "metadata": {},
   "source": [
    "#### 7.6 自定义分布式 Metric\n",
    "\n",
    "&emsp;&emsp;fastNLP 的评测方法支持用户进行自定义，并且也可以实现分布式训练中的评测细节。以下面经过简化的 `Accuracy` 为例，其基类 `Metric` 包含 `backend` 和 `aggregate_when_get_metric` 两个参数，后者表示在最终获得结果时是否需要进行 aggregate 操作。该 Metric  包含两个张量类型的成员 `correct` 和 `total` ，表示正确的预测和样本总数。由于我们需要它实现分布式的功能，因此必须调用 `register_element` 函数来注册该成员，并制定方法 `aggregate_method` 为 `sum` 来表示在分布式训练下需要将多个进程上的结果累加起来，最后再计算出正确率。\n",
    "\n",
    "&emsp;&emsp;一个 `Metric` 应该包含三个函数：\n",
    "\n",
    "- `reset`：在验证前调用，用于重置未注册成员的值。在 `Accuracy` 中由于成员均被注册，所以便没有重写该函数\n",
    "- `update`：对每个 batch 的数据进行处理，比如 `Accuracy` 会比较 pred 和 target 的值，来统计预测正确的数目和样本的总数\n",
    "- `get_metric`：在一个 dataloader 迭代结束后调用，用于生成结果。`Accuracy` 会计算出这次验证的正确率，然后返回。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "539cb7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fastNLP import Metric\n",
    "\n",
    "class Accuracy(Metric):\n",
    "\n",
    "    def __init__(self, backend, aggregate_when_get_metric = None):\n",
    "        super(Accuracy, self).__init__(backend=backend, aggregate_when_get_metric=aggregate_when_get_metric)\n",
    "        self.register_element(name='correct', value=0, aggregate_method='sum', backend=backend)\n",
    "        self.register_element(name='total', value=0, aggregate_method=\"sum\", backend=backend)\n",
    "\n",
    "    def get_metric(self) -> dict:\n",
    "        evaluate_result = {'acc': round(self.correct.get_scalar() / (self.total.get_scalar() + 1e-12), 6)}\n",
    "        return evaluate_result\n",
    "\n",
    "    def update(self, pred, target):\n",
    "\n",
    "        pred = pred.argmax(axis=-1)\n",
    "\n",
    "        self.total += np.prod(list(pred.shape)).item()\n",
    "        self.correct += (target == pred).sum().item()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9fd710e4",
   "metadata": {},
   "source": [
    "&emsp;&emsp;而关于分布式 Metric 的构建，我们可以借助 `torch.distributed.gather` 之类的函数来将多卡上的数据聚合到一处，然后进行更新。您可以参考 [SpanFPreRecMetric](../../api/generated/fastNLP.core.SpanFPreRecMetric.rst) 中的 `get_metric()` 方法将多个结果聚合在一起。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25623813",
   "metadata": {},
   "source": [
    "#### 7.7 更有效率的Sampler\n",
    "\n",
    "&emsp;&emsp;fastNLP 还提供了一些其它的 Sampler 或 BatchSampler 来实现更有效率的训练。\n",
    "\n",
    "- [BucketedBatchSampler](../../api/generated/fastNLP.core.BucketedBatchSampler.rst)：这种 BatchSampler 会首先按照 sample 的长度排序，然后以 batch_size\\*num_batch_per_bucket 为一个 `桶` 的大小，数据只会在这个桶内进行组\n",
    "    合，这样每个 batch 中的 padding 数量会比较少 （因为桶内的数据的长度都接近）。\n",
    "- [SortedSampler](../../api/generated/fastNLP.core.SortedSampler.rst)：这种 Sampler 会从长到短对数据进行迭代。\n",
    "\n",
    "&emsp;&emsp;因此，我们可以在训练时使用 `BucketedBatchSampler` 尽可能地减少 padding 数目并随机取样，在不需要随机采样的评估时使用 `SortedSampler` 来达到理论上 padding 最少的效果，提高训练的效率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63ef357a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09:43:30] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running evaluator sanity check for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> batches.              <a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/trainer.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">trainer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/trainer.py#661\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">661</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09:43:30]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running evaluator sanity check for \u001b[1;36m2\u001b[0m batches.              \u001b]8;id=160529;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/trainer.py\u001b\\\u001b[2mtrainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=180582;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/trainer.py#661\u001b\\\u001b[2m661\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb0c65cc60d946a5bfb8e4860e613450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e2e5c451f7489eb5e6a786a17755bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00d75f; text-decoration-color: #00d75f\">+++++++++++++++++++++++++++++ </span><span style=\"font-weight: bold\">Eval. results on Epoch:</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">, Batch:</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #00d75f; text-decoration-color: #00d75f\"> +++++++++++++++++++++++++++++</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;41m+++++++++++++++++++++++++++++ \u001b[0m\u001b[1mEval. results on Epoch:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m, Batch:\u001b[0m\u001b[1;36m0\u001b[0m\u001b[38;5;41m +++++++++++++++++++++++++++++\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"f#f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.749894</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"pre#f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.742511</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"rec#f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.757425</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[1;34m\"f#f\"\u001b[0m: \u001b[1;36m0.749894\u001b[0m,\n",
       "  \u001b[1;34m\"pre#f\"\u001b[0m: \u001b[1;36m0.742511\u001b[0m,\n",
       "  \u001b[1;34m\"rec#f\"\u001b[0m: \u001b[1;36m0.757425\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09:43:51] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> The best performance for monitor f#<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:0</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">749894</span> was <a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/progress_callback.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">progress_callback.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/progress_callback.py#37\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">37</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         achieved in Epoch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Global Batch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">217</span>. The        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         evaluation result:                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'f#f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.749894</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pre#f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.742511</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'rec#f'</span>:     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.757425</span><span style=\"font-weight: bold\">}</span>                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09:43:51]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m The best performance for monitor f#\u001b[1;92mf:0\u001b[0m.\u001b[1;36m749894\u001b[0m was \u001b]8;id=2566;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/progress_callback.py\u001b\\\u001b[2mprogress_callback.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=356757;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/progress_callback.py#37\u001b\\\u001b[2m37\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         achieved in Epoch:\u001b[1;36m1\u001b[0m, Global Batch:\u001b[1;36m217\u001b[0m. The        \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         evaluation result:                                \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[1m{\u001b[0m\u001b[32m'f#f'\u001b[0m: \u001b[1;36m0.749894\u001b[0m, \u001b[32m'pre#f'\u001b[0m: \u001b[1;36m0.742511\u001b[0m, \u001b[32m'rec#f'\u001b[0m:     \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[1;36m0.757425\u001b[0m\u001b[1m}\u001b[0m                                         \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading best model from buffer with f#f:  <a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/load_best_model_callback.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">load_best_model_callback.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/load_best_model_callback.py#115\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.749894</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading best model from buffer with f#f:  \u001b]8;id=801627;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/load_best_model_callback.py\u001b\\\u001b[2mload_best_model_callback.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=801765;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/load_best_model_callback.py#115\u001b\\\u001b[2m115\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[1;36m0.749894\u001b[0m\u001b[33m...\u001b[0m                               \u001b[2m                               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastNLP import prepare_torch_dataloader, BucketedBatchSampler, SortedSampler\n",
    "\n",
    "# 还是以上述 NER 任务为例\n",
    "# 实例化 BucketedBatchSampler\n",
    "train_batch_sampler = BucketedBatchSampler(\n",
    "    data_bundle.get_dataset(\"train\"),\n",
    "    batch_size=32,\n",
    "    length=\"input_len\",\n",
    "    num_batch_per_bucket=10,\n",
    ")\n",
    "train_dataloader = prepare_torch_dataloader(\n",
    "    data_bundle.get_dataset(\"train\"),\n",
    "    batch_sampler=train_batch_sampler\n",
    ")\n",
    "\n",
    "# 实例化 SortedSampler\n",
    "dev_sampler = SortedSampler(data_bundle.get_dataset(\"dev\"), length=\"input_len\")\n",
    "dev_dataloader = train_dataloader = prepare_torch_dataloader(\n",
    "    data_bundle.get_dataset(\"train\"),\n",
    "    sampler=dev_sampler,\n",
    ")\n",
    "\n",
    "# 设置训练模型和参数\n",
    "# model = BertNER('bert-base-uncased', len(data_bundle.get_vocab('target')), data_bundle.get_vocab('target'))\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "callbacks = [\n",
    "    LoadBestModelCallback(),   # 用于在训练结束之后加载性能最好的model的权重\n",
    "    TorchWarmupCallback()\n",
    "]\n",
    "\n",
    "trainer = Trainer(model=model, train_dataloader=train_dataloader, optimizers=optimizer, \n",
    "                  evaluate_dataloaders=dev_dataloader, \n",
    "                  metrics={'f': SpanFPreRecMetric(tag_vocab=data_bundle.get_vocab('target'))}, \n",
    "                  n_epochs=1, callbacks=callbacks, \n",
    "                  evaluate_input_mapping={'first_len': 'seq_len'},\n",
    "                  device=0, monitor='f#f', fp16=False)\n",
    "trainer.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b4c27b1",
   "metadata": {},
   "source": [
    "#### 7.8保存模型\n",
    "\n",
    "&emsp;&emsp;在 fastNLP 中，可以通过调用 Trainer 和 `save_model` 和 `load_model` 函数来保存和加载模型。参数 `only_state_dict` 会决定在保存或加载时是否仅处理模型的 state_dict，默认为 `True` 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d6da597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = BertNER('bert-base-uncased', len(data_bundle.get_vocab('target')), data_bundle.get_vocab('target'))\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n",
    "callbacks = [\n",
    "    LoadBestModelCallback(),   # 用于在训练结束之后加载性能最好的model的权重\n",
    "    TorchWarmupCallback(),\n",
    "]\n",
    "\n",
    "trainer = Trainer(model=model, train_dataloader=dls['train'], optimizers=optimizer, \n",
    "                  evaluate_dataloaders=dls['dev'], \n",
    "                  metrics={'f': SpanFPreRecMetric(tag_vocab=data_bundle.get_vocab('target'))}, \n",
    "                  n_epochs=1, callbacks=callbacks, \n",
    "                  evaluate_input_mapping={'first_len': 'seq_len'}, overfit_batches=0,\n",
    "                  device=0, monitor='f#f', fp16=False)\n",
    "trainer.save_model(\"model\", only_state_dict=True)\n",
    "trainer.load_model(\"model\", only_state_dict=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0141f525",
   "metadata": {},
   "source": [
    "&emsp;&emsp;同样，`Evaluator` 也提供了 `load_model` 接口，这样我们可以使用它来加载已经训练好的模型来进行评估或者测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2131907",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(model=model, dataloaders=dls['dev'],\n",
    "                  n_epochs=1, mapping={'first_len': 'seq_len'},\n",
    "                  device=0)\n",
    "evaluator.load_model(\"model\", only_state_dict=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c20a56c",
   "metadata": {},
   "source": [
    "#### 7.9 断点重训\n",
    "\n",
    "&emsp;&emsp;fastNLP 提供了断点重训的功能，配合 `CheckpointCallback` 和 `Trainer.run` 的 `resume_from` 参数便可以实现这一功能，使得我们可以从上一次保存的地方重新开始训练（精确到断点的 batch）。下面我们通过一个简单的例子来展示这一功能，可以看到加载前后的数据恰好构成一整个数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "443dab42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd319047cdf49b2a607c5bfe49f455a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09:44:09] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>.<span style=\"font-weight: bold\">]</span>,                                              <a href=\"file:///tmp/ipykernel_6930/21462856.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">21462856.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_6930/21462856.py#15\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                 <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>.<span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cuda:0'</span><span style=\"font-weight: bold\">)</span>                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09:44:09]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m9\u001b[0m.\u001b[1m]\u001b[0m,                                              \u001b]8;id=646953;file:///tmp/ipykernel_6930/21462856.py\u001b\\\u001b[2m21462856.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=137153;file:///tmp/ipykernel_6930/21462856.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                 \u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdevice\u001b[0m=\u001b[32m'cuda:0'\u001b[0m\u001b[1m)\u001b[0m                            \u001b[2m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>.<span style=\"font-weight: bold\">]</span>,                                              <a href=\"file:///tmp/ipykernel_6930/21462856.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">21462856.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_6930/21462856.py#15\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                 <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>.<span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cuda:0'</span><span style=\"font-weight: bold\">)</span>                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m7\u001b[0m.\u001b[1m]\u001b[0m,                                              \u001b]8;id=58614;file:///tmp/ipykernel_6930/21462856.py\u001b\\\u001b[2m21462856.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=179282;file:///tmp/ipykernel_6930/21462856.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                 \u001b[1m[\u001b[0m\u001b[1;36m4\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdevice\u001b[0m=\u001b[32m'cuda:0'\u001b[0m\u001b[1m)\u001b[0m                            \u001b[2m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>.<span style=\"font-weight: bold\">]</span>,                                             <a href=\"file:///tmp/ipykernel_6930/21462856.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">21462856.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_6930/21462856.py#15\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                 <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>.<span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cuda:0'</span><span style=\"font-weight: bold\">)</span>                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m5\u001b[0m.\u001b[1m]\u001b[0m,                                             \u001b]8;id=13894;file:///tmp/ipykernel_6930/21462856.py\u001b\\\u001b[2m21462856.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=976856;file:///tmp/ipykernel_6930/21462856.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                 \u001b[1m[\u001b[0m\u001b[1;36m11\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdevice\u001b[0m=\u001b[32m'cuda:0'\u001b[0m\u001b[1m)\u001b[0m                           \u001b[2m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.<span style=\"font-weight: bold\">]</span>,                                              <a href=\"file:///tmp/ipykernel_6930/21462856.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">21462856.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_6930/21462856.py#15\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                 <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>.<span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cuda:0'</span><span style=\"font-weight: bold\">)</span>                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m.\u001b[1m]\u001b[0m,                                              \u001b]8;id=803569;file:///tmp/ipykernel_6930/21462856.py\u001b\\\u001b[2m21462856.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=420754;file:///tmp/ipykernel_6930/21462856.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                 \u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdevice\u001b[0m=\u001b[32m'cuda:0'\u001b[0m\u001b[1m)\u001b[0m                            \u001b[2m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>.<span style=\"font-weight: bold\">]</span>,                                             <a href=\"file:///tmp/ipykernel_6930/21462856.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">21462856.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_6930/21462856.py#15\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                 <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>.<span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cuda:0'</span><span style=\"font-weight: bold\">)</span>                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m6\u001b[0m.\u001b[1m]\u001b[0m,                                             \u001b]8;id=579723;file:///tmp/ipykernel_6930/21462856.py\u001b\\\u001b[2m21462856.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=257888;file:///tmp/ipykernel_6930/21462856.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                 \u001b[1m[\u001b[0m\u001b[1;36m10\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdevice\u001b[0m=\u001b[32m'cuda:0'\u001b[0m\u001b[1m)\u001b[0m                           \u001b[2m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09:44:10] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>.<span style=\"font-weight: bold\">]</span>,                                              <a href=\"file:///tmp/ipykernel_6930/21462856.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">21462856.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_6930/21462856.py#15\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                 <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.<span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cuda:0'</span><span style=\"font-weight: bold\">)</span>                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09:44:10]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m8\u001b[0m.\u001b[1m]\u001b[0m,                                              \u001b]8;id=345085;file:///tmp/ipykernel_6930/21462856.py\u001b\\\u001b[2m21462856.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=895924;file:///tmp/ipykernel_6930/21462856.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                 \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdevice\u001b[0m=\u001b[32m'cuda:0'\u001b[0m\u001b[1m)\u001b[0m                            \u001b[2m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastNLP import DataSet, CheckpointCallback, logger\n",
    "\n",
    "# 构造一个简单的数据集\n",
    "dataset = DataSet({\"items\": [ [i * 1.0] for i in range(12)]})\n",
    "dataloader = prepare_dataloader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# 构造一个简单的模型\n",
    "class SimpleModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModule, self).__init__()\n",
    "        self.fc = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, items):\n",
    "        # 仅仅输出batch的内容\n",
    "        logger.info(items)\n",
    "        return {\"loss\": self.fc(items).sum()}\n",
    "\n",
    "test_model = SimpleModule()\n",
    "optimizer = optim.AdamW(test_model.parameters(), lr=2e-5)\n",
    "\n",
    "callbacks = [\n",
    "    # 每两个 batch 保存一次\n",
    "    CheckpointCallback(\"./checkpoint\", every_n_batches=2, save_object=\"trainer\")\n",
    "]\n",
    "trainer = Trainer(model=test_model, train_dataloader=dataloader, optimizers=optimizer, \n",
    "                  n_epochs=1, device=0, callbacks=callbacks)\n",
    "trainer.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45491e3f",
   "metadata": {},
   "source": [
    "&emsp;&emsp;在运行完上述代码后，您会发现在 `checkpoint` 文件夹下出现了我们保存的结果，包含时间、保存的 batch 数目。如果您想要从其中一个断点开始训练，可以运行下面代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e58bf6e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa34f11b17e43d6ab2dcdea1f3b315d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09:44:12] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>.<span style=\"font-weight: bold\">]</span>,                                             <a href=\"file:///tmp/ipykernel_6930/21462856.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">21462856.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_6930/21462856.py#15\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                 <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>.<span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cuda:0'</span><span style=\"font-weight: bold\">)</span>                           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09:44:12]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m6\u001b[0m.\u001b[1m]\u001b[0m,                                             \u001b]8;id=852159;file:///tmp/ipykernel_6930/21462856.py\u001b\\\u001b[2m21462856.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=708608;file:///tmp/ipykernel_6930/21462856.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                 \u001b[1m[\u001b[0m\u001b[1;36m10\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdevice\u001b[0m=\u001b[32m'cuda:0'\u001b[0m\u001b[1m)\u001b[0m                           \u001b[2m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>.<span style=\"font-weight: bold\">]</span>,                                              <a href=\"file:///tmp/ipykernel_6930/21462856.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">21462856.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_6930/21462856.py#15\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                 <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.<span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cuda:0'</span><span style=\"font-weight: bold\">)</span>                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">              </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m \u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m8\u001b[0m.\u001b[1m]\u001b[0m,                                              \u001b]8;id=124938;file:///tmp/ipykernel_6930/21462856.py\u001b\\\u001b[2m21462856.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=650106;file:///tmp/ipykernel_6930/21462856.py#15\u001b\\\u001b[2m15\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                 \u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m.\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdevice\u001b[0m=\u001b[32m'cuda:0'\u001b[0m\u001b[1m)\u001b[0m                            \u001b[2m              \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(model=test_model, train_dataloader=dataloader, optimizers=optimizer, \n",
    "                  n_epochs=1, device=0,)\n",
    "# 从 epoch 0 batch 4 开始重训\n",
    "trainer.run(resume_from=\"./checkpoint/2022-07-22-15_09_23_162748/trainer-epoch_0-batch_4\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b48067b",
   "metadata": {},
   "source": [
    "&emsp;&emsp;可以看到在迭代一轮的情况下，只进行了两次输出，因为当次训练是从 4 个 batch 之后开始的，只会训练剩下的 2 个 batch。且对比前后的输出可以发现我们取出的后 2 个 batch恰好能够和第一次输出的前 4 个 batch 构成一个完整的数据集，这也是 `可复现` 的含义。除了固定间隔的保存外，`CheckpointCallback` 还支持在每次迭代结束后保存、在出现异常信息时保存、在特定结果变好时保存。更多相关的参数可以阅读 [CheckpointCallback 的文档](../../api/generated/fastNLP.core.CheckpointCallback.rst) 。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99ae9fdb",
   "metadata": {},
   "source": [
    "#### 7.10 使用huggingface datasets\n",
    "\n",
    "&emsp;&emsp;fastNLP 还支持 `datasets` 库提供的多种数据集。不过在这种情况下，您需要自己使用 tokenizer 等对数据进行处理。以 `datasets` 提供的 `SetFit/sst2` 数据集为例，我们可以通过下面的代码进行处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e066bb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration SetFit--sst2-9a0ea0079d8ddf85\n",
      "Reusing dataset json (/remote-home/shxing/.cache/huggingface/datasets/SetFit___json/SetFit--sst2-9a0ea0079d8ddf85/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370347e94e944187ab1ead72373292f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /remote-home/shxing/.cache/huggingface/datasets/SetFit___json/SetFit--sst2-9a0ea0079d8ddf85/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-de22e6f9f2c3004c.arrow\n",
      "Loading cached shuffled indices for dataset at /remote-home/shxing/.cache/huggingface/datasets/SetFit___json/SetFit--sst2-9a0ea0079d8ddf85/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-c5d1cb16e7c8d9b0.arrow\n",
      "Loading cached shuffled indices for dataset at /remote-home/shxing/.cache/huggingface/datasets/SetFit___json/SetFit--sst2-9a0ea0079d8ddf85/0.0.0/a3e658c4731e59120d44081ac10bf85dc7e1388126b92338344ce9661907f253/cache-ba87bf1c556653d2.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+-------+------------+\n",
      "| text                         | label | label_text |\n",
      "+------------------------------+-------+------------+\n",
      "| this is the sort of low-g... | 0     | negative   |\n",
      "| the acting in pauline and... | 1     | positive   |\n",
      "| as dumb and cheesy as the... | 1     | positive   |\n",
      "| the title , alone , shoul... | 0     | negative   |\n",
      "| a smart , sassy and excep... | 1     | positive   |\n",
      "| the slapstick is labored ... | 0     | negative   |\n",
      "| you ... get a sense of go... | 0     | negative   |\n",
      "| what sets it apart is the... | 1     | positive   |\n",
      "| fifty years after the fac... | 1     | positive   |\n",
      "| in the new guy , even the... | 0     | negative   |\n",
      "| this sensitive , smart , ... | 1     | positive   |\n",
      "| with a large cast represe... | 1     | positive   |\n",
      "| ...                          | ...   | ...        |\n",
      "+------------------------------+-------+------------+\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8107bcfd7e214b2fb81d0369d1c1baef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91629f701c4f41abba8a157b0660b440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+------------+------------------+--------------------+--------------------+\n",
      "| text             | label | label_text | input_ids        | token_type_ids     | attention_mask     |\n",
      "+------------------+-------+------------+------------------+--------------------+--------------------+\n",
      "| this is the s... | 0     | negative   | [101, 2023, 2... | [0, 0, 0, 0, 0,... | [1, 1, 1, 1, 1,... |\n",
      "| the acting in... | 1     | positive   | [101, 1996, 3... | [0, 0, 0, 0, 0,... | [1, 1, 1, 1, 1,... |\n",
      "| as dumb and c... | 1     | positive   | [101, 2004, 1... | [0, 0, 0, 0, 0,... | [1, 1, 1, 1, 1,... |\n",
      "| the title , a... | 0     | negative   | [101, 1996, 2... | [0, 0, 0, 0, 0,... | [1, 1, 1, 1, 1,... |\n",
      "| a smart , sas... | 1     | positive   | [101, 1037, 6... | [0, 0, 0, 0, 0,... | [1, 1, 1, 1, 1,... |\n",
      "| the slapstick... | 0     | negative   | [101, 1996, 1... | [0, 0, 0, 0, 0,... | [1, 1, 1, 1, 1,... |\n",
      "| you ... get a... | 0     | negative   | [101, 2017, 1... | [0, 0, 0, 0, 0,... | [1, 1, 1, 1, 1,... |\n",
      "| what sets it ... | 1     | positive   | [101, 2054, 4... | [0, 0, 0, 0, 0,... | [1, 1, 1, 1, 1,... |\n",
      "| fifty years a... | 1     | positive   | [101, 5595, 2... | [0, 0, 0, 0, 0,... | [1, 1, 1, 1, 1,... |\n",
      "| in the new gu... | 0     | negative   | [101, 1999, 1... | [0, 0, 0, 0, 0,... | [1, 1, 1, 1, 1,... |\n",
      "| this sensitiv... | 1     | positive   | [101, 2023, 7... | [0, 0, 0, 0, 0,... | [1, 1, 1, 1, 1,... |\n",
      "| with a large ... | 1     | positive   | [101, 2007, 1... | [0, 0, 0, 0, 0,... | [1, 1, 1, 1, 1,... |\n",
      "| ...              | ...   | ...        | ...              | ...                | ...                |\n",
      "+------------------+-------+------------+------------------+--------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "from fastNLP.transformers.torch import AutoTokenizer # fastNLP 将 transformers 4.11.3 迁移了过来，可以直接进行调用\n",
    "from fastNLP.io import DataBundle\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 加载 torkenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# 使用 datasets 加载数据集\n",
    "sst2 = load_dataset(\"SetFit/sst2\").shuffle(seed=123)[\"train\"]\n",
    "\n",
    "# 获得验证集和测试集\n",
    "train_dataset = DataSet.from_pandas(sst2.to_pandas())\n",
    "train_dataset, val_dataset = train_dataset.split(ratio=0.8, shuffle=True)\n",
    "\n",
    "print(train_dataset)\n",
    "# 使用 DataBundle 进行包装和分词\n",
    "def _process(data):\n",
    "    # 按照句长 64 进行截断或填充\n",
    "    data = tokenizer(data, max_length=64, padding=\"max_length\")\n",
    "    return data\n",
    "\n",
    "sst2_data_bundle = DataBundle(\n",
    "    datasets={\"train\": train_dataset, \"val\": val_dataset}\n",
    ")\n",
    "\n",
    "# 对 text 列使用 _process 函数进行处理\n",
    "sst2_data_bundle.apply_field_more(\n",
    "    _process,\n",
    "    field_name=\"text\",\n",
    "    num_proc=5,\n",
    ")\n",
    "print(sst2_data_bundle.get_dataset(\"train\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ce4d737",
   "metadata": {},
   "source": [
    "#### 7.11 使用torchmetrics来作为metric\n",
    "\n",
    "&emsp;&emsp;fastNLP 的评测 metric 同样支持 `torchmetrics` 提供的各种评测方法，不仅仅局限于 fastNLP 的 `Metric` 类型。我们可以构造一个简单的数据集，并使用 `torchmetrics.Accuracy` 进行评估。注意，fastNLP 和 `torchmetrics` 的一些同名评测方法接受的参数名会有些许出入，您可以通过改变模型返回值或通过 `output_mapping` 等参数来进行调整。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80dba722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09:50:16] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running evaluator sanity check for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> batches.              <a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/trainer.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">trainer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/trainer.py#661\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">661</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09:50:16]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running evaluator sanity check for \u001b[1;36m2\u001b[0m batches.              \u001b]8;id=649680;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/trainer.py\u001b\\\u001b[2mtrainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=313696;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/trainer.py#661\u001b\\\u001b[2m661\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750d738848904dc7993279ee6e4f2527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e440e30c0d74ad987a53db443cc936d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------- Eval. results on Epoch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Batch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> -----------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------- Eval. results on Epoch:\u001b[1;36m1\u001b[0m, Batch:\u001b[1;36m0\u001b[0m -----------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"acc\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.05999999865889549</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[1;34m\"acc\"\u001b[0m: \u001b[1;36m0.05999999865889549\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchmetrics import Accuracy as TorchAccuracy # torchmetrics 的 Accuracy\n",
    "\n",
    "class ArgMaxDataset(Dataset):\n",
    "    \"\"\"\n",
    "    一个预测序列最大值的数据集\n",
    "    \"\"\"\n",
    "    def __init__(self, num_labels=10, data_num=1000):\n",
    "        self.num_labels = num_labels\n",
    "        self.data_num = data_num\n",
    "\n",
    "        self.x = torch.randint(low=-100, high=100, size=[data_num, num_labels]).float()\n",
    "        self.y = torch.max(self.x, dim=-1)[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_num\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return {\"x\": self.x[item], \"y\": self.y[item]}\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    简单的分类模型\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_dimension):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_features=feature_dimension, out_features=10)\n",
    "        self.ac1 = nn.ReLU()\n",
    "        self.output = nn.Linear(in_features=10, out_features=feature_dimension)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ac1(self.linear1(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "    def train_step(self, x, y):\n",
    "        x = self(x)\n",
    "        return {\"loss\": self.loss_fn(x, y)}\n",
    "\n",
    "    def evaluate_step(self, x, y):\n",
    "        x = self(x)\n",
    "        x = torch.max(x, dim=-1)[1]\n",
    "        # torchmetrics Accuracy 接受的第一个参数是 preds\n",
    "        return {\"preds\": x, \"target\": y}\n",
    "\n",
    "dataloaders = prepare_dataloader(\n",
    "    {\n",
    "        'train': ArgMaxDataset(10, 100),\n",
    "        'dev': ArgMaxDataset(10, 100),\n",
    "    },\n",
    "    batch_size=4,\n",
    ")\n",
    "classifier = Classifier(10)\n",
    "optimizer = optim.AdamW(classifier.parameters(), lr=2e-5)\n",
    "\n",
    "trainer = Trainer(model=classifier, train_dataloader=dataloaders['train'], optimizers=optimizer, \n",
    "                  evaluate_dataloaders=dataloaders['dev'], metrics={'acc': TorchAccuracy()}, # 这里是 torchmetrics 的 Accuracy \n",
    "                  n_epochs=1, device=0)\n",
    "trainer.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "368f64b5",
   "metadata": {},
   "source": [
    "#### 7.12 将预测结果写出到文件\n",
    "\n",
    "&emsp;&emsp;在训练时，我们有时会希望输出预测结果或是将结果保存到文件中。在 fastNLP 中，我们可以通过三种方法实现该功能。\n",
    "\n",
    "##### 通过 evaluate_batch_step_fn 实现\n",
    "\n",
    "&emsp;&emsp;`evaluate_batch_step_fn` 参数接受一个函数，该函数的接受两个参数 `evaluator` 和 `batch` 来处理一个 batch 的数据。对于我们上文定义的 `BertNER` 模型，我们可以自定义一个函数 `output_batch`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65b0ae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastNLP import logger\n",
    "\n",
    "def output_batch(evaluator, batch):\n",
    "    logger.info(f\"input:{batch['input_ids']}\")\n",
    "    output = evaluator.evaluate_step(batch)\n",
    "    logger.info(f\"prediction:{output['pred']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a52879a6",
   "metadata": {},
   "source": [
    "&emsp;&emsp;然后按照正常的流程进行训练即可。训练之后，调用 `Evaluator` 可以实现预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "484d4c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09:50:30] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> Some weights of the model checkpoint at            <a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/transformers/torch/modeling_utils.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">modeling_utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/transformers/torch/modeling_utils.py#1490\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1490</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         bert-base-uncased were not used when initializing  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         BertModel: <span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'cls.predictions.decoder.weight'</span>,      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'cls.predictions.bias'</span>,                            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'cls.predictions.transform.LayerNorm.weight'</span>,      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'cls.predictions.transform.dense.weight'</span>,          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'cls.predictions.transform.LayerNorm.bias'</span>,        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'cls.seq_relationship.bias'</span>,                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'cls.predictions.transform.dense.bias'</span>,            <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008000; text-decoration-color: #008000\">'cls.seq_relationship.weight'</span><span style=\"font-weight: bold\">]</span>                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         - This IS expected if you are initializing         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         BertModel from the checkpoint of a model trained   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         on another task or with another architecture <span style=\"font-weight: bold\">(</span>e.g. <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         initializing a BertForSequenceClassification model <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         from a BertForPreTraining model<span style=\"font-weight: bold\">)</span>.                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         - This IS NOT expected if you are initializing     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         BertModel from the checkpoint of a model that you  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         expect to be exactly identical <span style=\"font-weight: bold\">(</span>initializing a     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         BertForSequenceClassification model from a         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         BertForSequenceClassification model<span style=\"font-weight: bold\">)</span>.              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09:50:30]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Some weights of the model checkpoint at            \u001b]8;id=796867;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/transformers/torch/modeling_utils.py\u001b\\\u001b[2mmodeling_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=799227;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/transformers/torch/modeling_utils.py#1490\u001b\\\u001b[2m1490\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         bert-base-uncased were not used when initializing  \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         BertModel: \u001b[1m[\u001b[0m\u001b[32m'cls.predictions.decoder.weight'\u001b[0m,      \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'cls.predictions.bias'\u001b[0m,                            \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'cls.predictions.transform.LayerNorm.weight'\u001b[0m,      \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'cls.predictions.transform.dense.weight'\u001b[0m,          \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'cls.predictions.transform.LayerNorm.bias'\u001b[0m,        \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'cls.seq_relationship.bias'\u001b[0m,                       \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'cls.predictions.transform.dense.bias'\u001b[0m,            \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[32m'cls.seq_relationship.weight'\u001b[0m\u001b[1m]\u001b[0m                     \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         - This IS expected if you are initializing         \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         BertModel from the checkpoint of a model trained   \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         on another task or with another architecture \u001b[1m(\u001b[0me.g. \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         initializing a BertForSequenceClassification model \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         from a BertForPreTraining model\u001b[1m)\u001b[0m.                  \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         - This IS NOT expected if you are initializing     \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         BertModel from the checkpoint of a model that you  \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         expect to be exactly identical \u001b[1m(\u001b[0minitializing a     \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         BertForSequenceClassification model from a         \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         BertForSequenceClassification model\u001b[1m)\u001b[0m.              \u001b[2m                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> All the weights of BertModel were initialized from <a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/transformers/torch/modeling_utils.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">modeling_utils.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/transformers/torch/modeling_utils.py#1507\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1507</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         the model checkpoint at bert-base-uncased.         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         If your task is similar to the task the model of   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         the checkpoint was trained on, you can already use <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         BertModel for predictions without further          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         training.                                          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                      </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m All the weights of BertModel were initialized from \u001b]8;id=50181;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/transformers/torch/modeling_utils.py\u001b\\\u001b[2mmodeling_utils.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776527;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/transformers/torch/modeling_utils.py#1507\u001b\\\u001b[2m1507\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         the model checkpoint at bert-base-uncased.         \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         If your task is similar to the task the model of   \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         the checkpoint was trained on, you can already use \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         BertModel for predictions without further          \u001b[2m                      \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         training.                                          \u001b[2m                      \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running evaluator sanity check for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> batches.              <a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/trainer.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">trainer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/trainer.py#661\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">661</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running evaluator sanity check for \u001b[1;36m2\u001b[0m batches.              \u001b]8;id=887303;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/trainer.py\u001b\\\u001b[2mtrainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=453413;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/trainer.py#661\u001b\\\u001b[2m661\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b0557c88a034009b2cbf67b33b5b28f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1870eafb0e364ab9a49f713e678fdf9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00d75f; text-decoration-color: #00d75f\">+++++++++++++++++++++++++++++ </span><span style=\"font-weight: bold\">Eval. results on Epoch:</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">, Batch:</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #00d75f; text-decoration-color: #00d75f\"> +++++++++++++++++++++++++++++</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;41m+++++++++++++++++++++++++++++ \u001b[0m\u001b[1mEval. results on Epoch:\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m, Batch:\u001b[0m\u001b[1;36m0\u001b[0m\u001b[38;5;41m +++++++++++++++++++++++++++++\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"f#f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01781</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"pre#f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.040142</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"rec#f\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.011444</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[1;34m\"f#f\"\u001b[0m: \u001b[1;36m0.01781\u001b[0m,\n",
       "  \u001b[1;34m\"pre#f\"\u001b[0m: \u001b[1;36m0.040142\u001b[0m,\n",
       "  \u001b[1;34m\"rec#f\"\u001b[0m: \u001b[1;36m0.011444\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09:50:35] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> The best performance for monitor f#<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">f:0</span>.<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01781</span> was  <a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/progress_callback.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">progress_callback.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/progress_callback.py#37\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">37</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         achieved in Epoch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Global Batch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>. The          <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         evaluation result:                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'f#f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01781</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pre#f'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.040142</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'rec#f'</span>:      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.011444</span><span style=\"font-weight: bold\">}</span>                                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                       </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09:50:35]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m The best performance for monitor f#\u001b[1;92mf:0\u001b[0m.\u001b[1;36m01781\u001b[0m was  \u001b]8;id=142968;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/progress_callback.py\u001b\\\u001b[2mprogress_callback.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=395417;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/progress_callback.py#37\u001b\\\u001b[2m37\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         achieved in Epoch:\u001b[1;36m1\u001b[0m, Global Batch:\u001b[1;36m5\u001b[0m. The          \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         evaluation result:                                \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[1m{\u001b[0m\u001b[32m'f#f'\u001b[0m: \u001b[1;36m0.01781\u001b[0m, \u001b[32m'pre#f'\u001b[0m: \u001b[1;36m0.040142\u001b[0m, \u001b[32m'rec#f'\u001b[0m:      \u001b[2m                       \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[1;36m0.011444\u001b[0m\u001b[1m}\u001b[0m                                         \u001b[2m                       \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading best model from buffer with f#f:  <a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/load_best_model_callback.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">load_best_model_callback.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/load_best_model_callback.py#115\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">115</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.01781</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading best model from buffer with f#f:  \u001b]8;id=620717;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/load_best_model_callback.py\u001b\\\u001b[2mload_best_model_callback.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=937515;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/callbacks/load_best_model_callback.py#115\u001b\\\u001b[2m115\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[1;36m0.01781\u001b[0m\u001b[33m...\u001b[0m                                \u001b[2m                               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f803a0b7294310b2f1bc6cbc884f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> input:<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">118</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">141</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,   <a href=\"file:///tmp/ipykernel_6930/2044833677.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2044833677.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_6930/2044833677.py#4\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>,                                                       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                 <span style=\"font-weight: bold\">[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">156</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9244</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                 <span style=\"font-weight: bold\">[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11896</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3309</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                 <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                 <span style=\"font-weight: bold\">[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15919</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1116</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                 <span style=\"font-weight: bold\">[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1398</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1300</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                 <span style=\"font-weight: bold\">[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">101</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">118</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">141</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,     <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cuda:0'</span><span style=\"font-weight: bold\">)</span>                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m input:\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m  \u001b[1;36m101\u001b[0m,   \u001b[1;36m118\u001b[0m,   \u001b[1;36m141\u001b[0m,  \u001b[33m...\u001b[0m,     \u001b[1;36m0\u001b[0m,     \u001b[1;36m0\u001b[0m,   \u001b]8;id=69468;file:///tmp/ipykernel_6930/2044833677.py\u001b\\\u001b[2m2044833677.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=770812;file:///tmp/ipykernel_6930/2044833677.py#4\u001b\\\u001b[2m4\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m         \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m,                                                       \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                 \u001b[1m[\u001b[0m  \u001b[1;36m101\u001b[0m,   \u001b[1;36m156\u001b[0m,  \u001b[1;36m9244\u001b[0m,  \u001b[33m...\u001b[0m,     \u001b[1;36m0\u001b[0m,     \u001b[1;36m0\u001b[0m,     \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m, \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                 \u001b[1m[\u001b[0m  \u001b[1;36m101\u001b[0m, \u001b[1;36m11896\u001b[0m,  \u001b[1;36m3309\u001b[0m,  \u001b[33m...\u001b[0m,     \u001b[1;36m0\u001b[0m,     \u001b[1;36m0\u001b[0m,     \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m, \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                 \u001b[33m...\u001b[0m,                                              \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                 \u001b[1m[\u001b[0m  \u001b[1;36m101\u001b[0m, \u001b[1;36m15919\u001b[0m,  \u001b[1;36m1116\u001b[0m,  \u001b[33m...\u001b[0m,     \u001b[1;36m0\u001b[0m,     \u001b[1;36m0\u001b[0m,     \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m, \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                 \u001b[1m[\u001b[0m  \u001b[1;36m101\u001b[0m,  \u001b[1;36m1398\u001b[0m,  \u001b[1;36m1300\u001b[0m,  \u001b[33m...\u001b[0m,     \u001b[1;36m0\u001b[0m,     \u001b[1;36m0\u001b[0m,     \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m, \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                 \u001b[1m[\u001b[0m  \u001b[1;36m101\u001b[0m,   \u001b[1;36m118\u001b[0m,   \u001b[1;36m141\u001b[0m,  \u001b[33m...\u001b[0m,     \u001b[1;36m0\u001b[0m,     \u001b[1;36m0\u001b[0m,         \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m         \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdevice\u001b[0m=\u001b[32m'cuda:0'\u001b[0m\u001b[1m)\u001b[0m                                     \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> prediction:<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">]</span>,              <a href=\"file:///tmp/ipykernel_6930/2044833677.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2044833677.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_6930/2044833677.py#6\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                 <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">]</span>,                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                 <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">]</span>,                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                 <span style=\"color: #808000; text-decoration-color: #808000\">...</span>,                                              <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                 <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">]</span>,                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                 <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>,                         <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                 <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>,  <span style=\"color: #808000; text-decoration-color: #808000\">...</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cuda:0'</span><span style=\"font-weight: bold\">)</span>       <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m prediction:\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m8\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m]\u001b[0m,              \u001b]8;id=742913;file:///tmp/ipykernel_6930/2044833677.py\u001b\\\u001b[2m2044833677.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=589604;file:///tmp/ipykernel_6930/2044833677.py#6\u001b\\\u001b[2m6\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m           \u001b[0m                 \u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m]\u001b[0m,                         \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                 \u001b[1m[\u001b[0m\u001b[1;36m7\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m6\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m]\u001b[0m,                         \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                 \u001b[33m...\u001b[0m,                                              \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                 \u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m]\u001b[0m,                         \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                 \u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m,                         \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m                 \u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m8\u001b[0m,  \u001b[33m...\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdevice\u001b[0m=\u001b[32m'cuda:0'\u001b[0m\u001b[1m)\u001b[0m       \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import optim\n",
    "from fastNLP import Trainer, LoadBestModelCallback, TorchWarmupCallback, Evaluator\n",
    "from fastNLP import SpanFPreRecMetric\n",
    "model_ner = BertNER('bert-base-uncased', len(data_bundle.get_vocab('target')), data_bundle.get_vocab('target'))\n",
    "optimizer = optim.AdamW(model_ner.parameters(), lr=2e-5)\n",
    "callbacks = [\n",
    "    LoadBestModelCallback(),   # 用于在训练结束之后加载性能最好的model的权重\n",
    "    TorchWarmupCallback()\n",
    "]\n",
    "\n",
    "trainer = Trainer(model=model_ner, train_dataloader=dls['train'], optimizers=optimizer, \n",
    "                  evaluate_dataloaders=dls['dev'], \n",
    "                  metrics={'f': SpanFPreRecMetric(tag_vocab=data_bundle.get_vocab('target'))}, \n",
    "                  n_epochs=1, callbacks=callbacks, \n",
    "                  evaluate_input_mapping={'first_len': 'seq_len'}, overfit_batches=0,\n",
    "                  device=0, monitor='f#f', fp16=False)\n",
    "trainer.run(5)\n",
    "\n",
    "evaluator = Evaluator(model=model_ner, dataloaders=dls['test'], \n",
    "                      evaluate_input_mapping={'first_len': 'seq_len'}, \n",
    "                      evaluate_batch_step_fn=output_batch, # evaluate_batch_step_fn\n",
    "                      device=0)\n",
    "evaluator.run(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59acd0e2",
   "metadata": {},
   "source": [
    "##### 通过 Metric 实现\n",
    "\n",
    "&emsp;&emsp;第二种方法是利用 Metric 进行输出或者保存。虽然 Metric 是用于评测的类，但其 **收集每个 batch 的数据 - 最后进行统一运算** 的过程也可以用于数据结果或者保存函数。并且由于 fastNLP 同样支持分布式的 Metric，因此该方法也可以在分布式训练中有相当不错的表现。比如我们想要实现一个将所有预测结果写入 `output.txt` 的功能呢，可以按如下方式编写："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6a205f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3930af5b684c4721a76f21a1a31934db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09:50:47] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> Metric:output returns <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span> when getting metric results.  <a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/evaluator.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">evaluator.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/evaluator.py#529\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">529</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09:50:47]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m Metric:output returns \u001b[3;35mNone\u001b[0m when getting metric results.  \u001b]8;id=245516;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/evaluator.py\u001b\\\u001b[2mevaluator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=641709;file:///remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/controllers/evaluator.py#529\u001b\\\u001b[2m529\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class OutputSaver(Metric):\n",
    "    def __init__(self, tag_vocab, filename):\n",
    "        super(OutputSaver, self).__init__()\n",
    "        self.tag_vocab = tag_vocab\n",
    "        self.filename = filename\n",
    "        self.words_list = []\n",
    "        self.targets_list = []\n",
    "        self.labels_list = []\n",
    "\n",
    "    def reset(self):\n",
    "        self.words_list = []\n",
    "        self.targets_list = []\n",
    "        self.labels_list = []\n",
    "\n",
    "    def update(self, pred, raw_words, target):\n",
    "        for words, single_target, output in zip(raw_words, target, pred):\n",
    "            # 收集数据、预测标签和真实标签\n",
    "            # 通过词表转换为字符串形式的结果\n",
    "            labels = [data_bundle.get_vocab(\"target\").idx2word[idx] for idx in output[:len(words)].tolist() ]\n",
    "            # 由于我们在前文使用 set_ignore 将 raw_target 忽略了，因此这里是无法获取到 raw_target 的，只能手动转换\n",
    "            # 当然这只是演示用，实际请根据需求调整是否忽略数据的某一列\n",
    "            raw_target = [data_bundle.get_vocab(\"target\").idx2word[idx] for idx in single_target[:len(words)].tolist() ]\n",
    "            self.words_list.append(words)\n",
    "            self.targets_list.append(raw_target)\n",
    "            self.labels_list.append(labels)\n",
    "\n",
    "    def get_metric(self):\n",
    "        with open(self.filename, \"w\") as f:\n",
    "            # 逐行写入文件\n",
    "            for words, targets, labels in zip(self.words_list, self.targets_list, self.labels_list):\n",
    "                f.write(\" \".join(words) + \"\\n\")\n",
    "                f.write(\" \".join(labels) + \"\\n\")\n",
    "                f.write(\" \".join(targets) + \"\\n\")\n",
    "                f.write(\"\\n\")\n",
    "\n",
    "evaluator = Evaluator(model=model, dataloaders=dls[\"test\"], \n",
    "                      device=0, n_epochs=1,\n",
    "                      metrics={\"output\": OutputSaver(data_bundle.get_vocab(\"target\"), \"output.txt\")})\n",
    "evaluator.run()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03a104dc",
   "metadata": {},
   "source": [
    "&emsp;&emsp;如果您想在分布式训练中实现这一功能，那么您也可以借助  `all_gather_object` 或 `all_gather` 并行操作进行输出：\n",
    "\n",
    "```python\n",
    "import torch.distributed as dist\n",
    "from fastNLP import Metric\n",
    "\n",
    "class Output(Metric):\n",
    "\n",
    "    def __init__(self, backend, aggregate_when_get_metric = None):\n",
    "        super(Output, self).__init__(backend=backend, aggregate_when_get_metric=aggregate_when_get_metric)\n",
    "        self.preds = []\n",
    "\n",
    "    def get_metric(self) -> dict:\n",
    "        gathered_preds = [None for _ in range(dist.get_world_size())]\n",
    "        # 收集其它 rank 的数据\n",
    "        torch.distributed.all_gather_object(gathered_preds, self.preds)\n",
    "        if dist.get_rank() == 0:\n",
    "            # 仅在 rank 0 输出\n",
    "            for rank, preds in gathered_preds:\n",
    "                print(\"prediction of rank\", rank)\n",
    "                for input_ids, pred in preds:\n",
    "                    print(\"input_ids\", input_ids)\n",
    "                    print(\"prediction\", pred)\n",
    "\n",
    "    def update(self, input_ids, pred):\n",
    "        # 添加到 preds 中\n",
    "        self.preds.append((input_ids, pred))\n",
    "\n",
    "    def reset(self):\n",
    "        self.preds = []\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a407012",
   "metadata": {},
   "source": [
    "##### 通过 evaluate_fn 实现\n",
    "\n",
    "&emsp;&emsp;第三种方法是通过指定 `evaluate_fn` 实现，即在模型中添加一个函数，然后进行训练，相当于将第一种方法的 `output_batch` 函数作为模型的成员函数。不过这种方法会涉及对模型的修改，因此不如前两种方法灵活，这里就不做赘述了。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc7be84b",
   "metadata": {},
   "source": [
    "#### 7.13 混合 dataset 训练\n",
    "\n",
    "&emsp;&emsp;在某些任务中，可能需要您使用多个数据集进行训练，而 fastNLP 也提供了这一功能，通过调用 `fastNLP.core.dataloaders.MixDataLoader` 实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39ceafc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'sequential' 模式表示按顺序取数据：\n",
      "{'items': tensor([[0, 0, 0],\n",
      "        [1, 1, 1]])}\n",
      "{'items': tensor([[2, 2, 2],\n",
      "        [3, 3, 3]])}\n",
      "{'items': tensor([[4, 4],\n",
      "        [5, 5]])}\n",
      "{'items': tensor([[6, 6],\n",
      "        [7, 7]])}\n",
      "'mix' 模式表示将数据混合后随机取样：\n",
      "{'items': tensor([[4, 4, 0],\n",
      "        [0, 0, 0]])}\n",
      "{'items': tensor([[1, 1, 1],\n",
      "        [5, 5, 0]])}\n",
      "{'items': tensor([[2, 2, 2],\n",
      "        [3, 3, 3]])}\n",
      "{'items': tensor([[6, 6],\n",
      "        [7, 7]])}\n",
      "'polling' 模式表示依次从每个数据集中轮询取数据：\n",
      "{'items': tensor([[0, 0, 0],\n",
      "        [1, 1, 1]])}\n",
      "{'items': tensor([[4, 4],\n",
      "        [5, 5]])}\n",
      "{'items': tensor([[2, 2, 2],\n",
      "        [3, 3, 3]])}\n",
      "{'items': tensor([[6, 6],\n",
      "        [7, 7]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/remote-home/shxing/anaconda3/envs/fastnlp/lib/python3.7/site-packages/fastNLP/core/samplers/mix_sampler.py:239: UserWarning: you are shuffling a 'array' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(total_index)\n"
     ]
    }
   ],
   "source": [
    "from fastNLP.core.dataloaders import MixDataLoader\n",
    "from fastNLP import DataSet\n",
    "\n",
    "# 生成顺序数据集，并且数据长度各不相同\n",
    "datasets = {\n",
    "    \"first\": DataSet({\"items\": [ [i, i, i] for i in range(4)]}),\n",
    "    \"second\": DataSet({\"items\": [ [i, i] for i in range(4, 8)]}),\n",
    "}\n",
    "\n",
    "print(\"'sequential' 模式表示按顺序取数据：\")\n",
    "mix_dataloader = MixDataLoader(datasets, batch_size=2, mode='sequential')\n",
    "for batch in mix_dataloader:\n",
    "    print(batch)\n",
    "\n",
    "print(\"'mix' 模式表示将数据混合后随机取样：\")\n",
    "mix_dataloader = MixDataLoader(datasets, batch_size=2, mode='mix')\n",
    "for batch in mix_dataloader:\n",
    "    print(batch)\n",
    "\n",
    "print(\"'polling' 模式表示依次从每个数据集中轮询取数据：\")\n",
    "mix_dataloader = MixDataLoader(datasets, batch_size=2, mode='polling')\n",
    "for batch in mix_dataloader:\n",
    "    print(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23501be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds_ratio='truncate_to_least' 会舍弃较大数据集的部分数据：\n",
      "{'items': tensor([[0, 0, 0],\n",
      "        [1, 1, 1]])}\n",
      "{'items': tensor([[2, 2, 2],\n",
      "        [3, 3, 3]])}\n",
      "{'items': tensor([[4, 4],\n",
      "        [5, 5]])}\n",
      "{'items': tensor([[6, 6],\n",
      "        [7, 7]])}\n",
      "ds_ratio='pad_to_most' 会对较小的数据集进行重采样：\n",
      "{'items': tensor([[0, 0, 0],\n",
      "        [1, 1, 1]])}\n",
      "{'items': tensor([[2, 2, 2],\n",
      "        [3, 3, 3]])}\n",
      "{'items': tensor([[0, 0, 0],\n",
      "        [1, 1, 1]])}\n",
      "{'items': tensor([[4, 4],\n",
      "        [5, 5]])}\n",
      "{'items': tensor([[6, 6],\n",
      "        [7, 7]])}\n",
      "{'items': tensor([[8, 8],\n",
      "        [9, 9]])}\n"
     ]
    }
   ],
   "source": [
    "# 生成顺序数据集，并且数据长度各不相同、总长也不同\n",
    "datasets = {\n",
    "    \"first\": DataSet({\"items\": [ [i, i, i] for i in range(4)]}),\n",
    "    \"second\": DataSet({\"items\": [ [i, i] for i in range(4, 10)]}),\n",
    "}\n",
    "\n",
    "print(\"ds_ratio='truncate_to_least' 会舍弃较大数据集的部分数据：\")\n",
    "mix_dataloader = MixDataLoader(datasets, batch_size=2, ds_ratio='truncate_to_least')\n",
    "for batch in mix_dataloader:\n",
    "    print(batch)\n",
    "\n",
    "print(\"ds_ratio='pad_to_most' 会对较小的数据集进行重采样：\")\n",
    "mix_dataloader = MixDataLoader(datasets, batch_size=2, ds_ratio='pad_to_most')\n",
    "for batch in mix_dataloader:\n",
    "    print(batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8719823a",
   "metadata": {},
   "source": [
    "&emsp;&emsp;您可以查阅 [MixDataLoader 的文档](../../api/generated/fastNLP.core.MixDataLoader.rst) 来详细了解它的用法。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4407f7c",
   "metadata": {},
   "source": [
    "#### 7.14 logger的使用\n",
    "\n",
    "&emsp;&emsp;fastNLP 的 `logger` 模块可以帮助您打印训练中的各种信息，让您一目了然地了解训练过程。其中 `rank_zero_warning` 可以在分布式训练中使用，只会在 rank 0 上输出警告，`warning_once` 则表示这条警告只会输出一次。`print` 函数则会将输入的内容输出为 INFO 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fed6d0df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09:50:53] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> information                                                <a href=\"file:///tmp/ipykernel_6930/428786443.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">428786443.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_6930/428786443.py#3\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09:50:53]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m information                                                \u001b]8;id=804116;file:///tmp/ipykernel_6930/428786443.py\u001b\\\u001b[2m428786443.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=614645;file:///tmp/ipykernel_6930/428786443.py#3\u001b\\\u001b[2m3\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> warning                                                    <a href=\"file:///tmp/ipykernel_6930/428786443.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">428786443.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_6930/428786443.py#4\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m warning                                                    \u001b]8;id=940360;file:///tmp/ipykernel_6930/428786443.py\u001b\\\u001b[2m428786443.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=184056;file:///tmp/ipykernel_6930/428786443.py#4\u001b\\\u001b[2m4\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> warning                                                    <a href=\"file:///tmp/ipykernel_6930/428786443.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">428786443.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_6930/428786443.py#5\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">5</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m warning                                                    \u001b]8;id=91051;file:///tmp/ipykernel_6930/428786443.py\u001b\\\u001b[2m428786443.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=168002;file:///tmp/ipykernel_6930/428786443.py#5\u001b\\\u001b[2m5\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> warning                                                    <a href=\"file:///tmp/ipykernel_6930/428786443.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">428786443.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_6930/428786443.py#6\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">6</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m warning                                                    \u001b]8;id=748837;file:///tmp/ipykernel_6930/428786443.py\u001b\\\u001b[2m428786443.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=772001;file:///tmp/ipykernel_6930/428786443.py#6\u001b\\\u001b[2m6\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">ERROR   </span> error                                                      <a href=\"file:///tmp/ipykernel_6930/428786443.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">428786443.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_6930/428786443.py#7\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">7</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31mERROR   \u001b[0m error                                                      \u001b]8;id=739810;file:///tmp/ipykernel_6930/428786443.py\u001b\\\u001b[2m428786443.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=745954;file:///tmp/ipykernel_6930/428786443.py#7\u001b\\\u001b[2m7\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> print as info                                              <a href=\"file:///tmp/ipykernel_6930/428786443.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">428786443.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_6930/428786443.py#9\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">9</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m print as info                                              \u001b]8;id=775202;file:///tmp/ipykernel_6930/428786443.py\u001b\\\u001b[2m428786443.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=964443;file:///tmp/ipykernel_6930/428786443.py#9\u001b\\\u001b[2m9\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastNLP import logger, print\n",
    "\n",
    "logger.info(\"information\")\n",
    "logger.warn(\"warning\")\n",
    "logger.rank_zero_warning(\"warning\")\n",
    "logger.warning_once(\"warning\")\n",
    "logger.error(\"error\")\n",
    "\n",
    "print(\"print as info\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "218099ba",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 7.15 Metric以下划线开头的指标不会打印\n",
    "\n",
    "&emsp;&emsp;`fastNLP` 中的 `progress_bar` 会自动过滤掉以 `_` 开头的评价指标，可以过滤掉用户不希望展示在终端的指标，在下面我们自定义的 `metric` 中，`_hidden` 是不会打印的，`progress_bar` 会从列表中过滤，请看示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ab0185d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastNLP import Metric\n",
    "class Accuracy(Metric):\n",
    "\n",
    "    def __init__(self, backend=\"torch\", aggregate_when_get_metric = None):\n",
    "        super(Accuracy, self).__init__(backend=backend, aggregate_when_get_metric=aggregate_when_get_metric)\n",
    "        self.register_element(name='correct', value=0, aggregate_method='sum', backend=backend)\n",
    "        self.register_element(name='total', value=0, aggregate_method=\"sum\", backend=backend)\n",
    "\n",
    "    def get_metric(self) -> dict:\n",
    "        evaluate_result = {'acc': round(self.correct.get_scalar() / (self.total.get_scalar() + 1e-12), 6),\n",
    "                           '_hidden': round(self.correct.get_scalar() / (self.total.get_scalar() + 1e-12), 6),\n",
    "                           'hidden': round(self.correct.get_scalar() / (self.total.get_scalar() + 1e-12), 6)}\n",
    "        return evaluate_result\n",
    "\n",
    "    def update(self, pred, target):\n",
    "\n",
    "        pred = pred.argmax(axis=-1)\n",
    "\n",
    "        self.total += np.prod(list(pred.shape)).item()\n",
    "        self.correct += (target == pred).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab21be57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[19:48:09] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Running evaluator sanity check for <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> batches.              <a href=\"file:///remote-home/kychen/anaconda3/envs/pytorch2/lib/python3.8/site-packages/fastNLP/core/controllers/trainer.py\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">trainer.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///remote-home/kychen/anaconda3/envs/pytorch2/lib/python3.8/site-packages/fastNLP/core/controllers/trainer.py#661\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">661</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[19:48:09]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Running evaluator sanity check for \u001b[1;36m2\u001b[0m batches.              \u001b]8;id=67801;file:///remote-home/kychen/anaconda3/envs/pytorch2/lib/python3.8/site-packages/fastNLP/core/controllers/trainer.py\u001b\\\u001b[2mtrainer.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=104711;file:///remote-home/kychen/anaconda3/envs/pytorch2/lib/python3.8/site-packages/fastNLP/core/controllers/trainer.py#661\u001b\\\u001b[2m661\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">----------------------------- Eval. results on Epoch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, Batch:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> -----------------------------\n",
       "</pre>\n"
      ],
      "text/plain": [
       "----------------------------- Eval. results on Epoch:\u001b[1;36m1\u001b[0m, Batch:\u001b[1;36m0\u001b[0m -----------------------------\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"acc#acc\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.32</span>,\n",
       "  <span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">\"hidden#acc\"</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.32</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "  \u001b[1;34m\"acc#acc\"\u001b[0m: \u001b[1;36m0.32\u001b[0m,\n",
       "  \u001b[1;34m\"hidden#acc\"\u001b[0m: \u001b[1;36m0.32\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from fastNLP import prepare_dataloader, Trainer\n",
    "\n",
    "\n",
    "class ArgMaxDataset(Dataset):\n",
    "    \"\"\"\n",
    "    一个预测序列最大值的数据集\n",
    "    \"\"\"\n",
    "    def __init__(self, num_labels=10, data_num=1000):\n",
    "        self.num_labels = num_labels\n",
    "        self.data_num = data_num\n",
    "\n",
    "        self.x = torch.randint(low=-100, high=100, size=[data_num, num_labels]).float()\n",
    "        self.y = torch.max(self.x, dim=-1)[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_num\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return {\"x\": self.x[item], \"y\": self.y[item]}\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    简单的分类模型\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_dimension):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_features=feature_dimension, out_features=10)\n",
    "        self.ac1 = nn.ReLU()\n",
    "        self.output = nn.Linear(in_features=10, out_features=feature_dimension)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.ac1(self.linear1(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "    def train_step(self, x, y):\n",
    "        x = self(x)\n",
    "        return {\"loss\": self.loss_fn(x, y)}\n",
    "\n",
    "    def evaluate_step(self, x, y):\n",
    "        x = self(x)\n",
    "        x = torch.max(x, dim=-1)[1]\n",
    "        return {\"pred\": x, \"target\": y}\n",
    "\n",
    "dataloaders = prepare_dataloader(\n",
    "    {\n",
    "        'train': ArgMaxDataset(10, 100),\n",
    "        'dev': ArgMaxDataset(10, 100),\n",
    "    },\n",
    "    batch_size=4,\n",
    ")\n",
    "classifier = Classifier(10)\n",
    "optimizer = optim.AdamW(classifier.parameters(), lr=2e-5)\n",
    "\n",
    "trainer = Trainer(model=classifier, train_dataloader=dataloaders['train'], optimizers=optimizer,\n",
    "                  evaluate_dataloaders=dataloaders['dev'], metrics={'acc': Accuracy()},\n",
    "                  n_epochs=1, device=0)\n",
    "trainer.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8c0ca2bf6db0e7c6e3389aab82556c6aa6e71021cc09850836374d19b3cd5b41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
